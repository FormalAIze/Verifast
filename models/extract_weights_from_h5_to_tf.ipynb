{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:09:43.523841Z",
     "start_time": "2020-08-04T05:09:41.705754Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from builtins import range, map, zip, filter\n",
    "from io import open\n",
    "import six,imp,os,sys\n",
    "from six.moves import cPickle\n",
    "import h5py\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold , train_test_split\n",
    "# from skimage.transform import resize\n",
    "import keras\n",
    "from keras.datasets import mnist,cifar10,fashion_mnist\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten,Conv1D, Conv2D, Convolution2D, MaxPooling1D,MaxPooling2D,Permute\n",
    "from keras.layers import GlobalAveragePooling2D, CuDNNGRU,CuDNNLSTM,LSTM#,AtrousConv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications import densenet,resnet50\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import keras.applications.vgg16 as vgg16\n",
    "from keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.losses import MAE\n",
    "from keras.optimizers import SGD, Adam, adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow import set_random_seed\n",
    "# from PIL import Image\n",
    "from numpy.random import seed\n",
    "keras.__version__\n",
    "# seed(639)\n",
    "# set_random_seed(5944)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kera-LSUV初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T08:41:18.437734Z",
     "start_time": "2020-01-03T08:41:18.392680Z"
    }
   },
   "outputs": [],
   "source": [
    "def svd_orthonormal(shape):\n",
    "    # Orthonorm init code is taked from Lasagne\n",
    "    # https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\n",
    "    if len(shape) < 2:\n",
    "        raise RuntimeError(\"Only shapes of length 2 or more are supported.\")\n",
    "    flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "    a = np.random.standard_normal(flat_shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == flat_shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return q\n",
    "\n",
    "\n",
    "def get_activations(model, layer, X_batch):\n",
    "    intermediate_layer_model = Model(\n",
    "        inputs=model.get_input_at(0),\n",
    "        outputs=layer.get_output_at(0)\n",
    "    )\n",
    "    activations = intermediate_layer_model.predict(X_batch)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def LSUVinit(model, batch, verbose=True, margin=0.1, max_iter=10):\n",
    "    # only these layer classes considered for LSUV initialization; add more if needed\n",
    "    classes_to_consider = (Dense, Convolution2D)\n",
    "\n",
    "    needed_variance = 1.0\n",
    "\n",
    "    layers_inintialized = 0\n",
    "    for layer in model.layers:\n",
    "        if verbose:\n",
    "            print(layer.name)\n",
    "        if not isinstance(layer, classes_to_consider):\n",
    "            continue\n",
    "        # avoid small layers where activation variance close to zero, esp. for small batches\n",
    "        if np.prod(layer.get_output_shape_at(0)[1:]) < 32:\n",
    "            if verbose:\n",
    "                print(layer.name, 'too small')\n",
    "            continue\n",
    "        if verbose:\n",
    "            print('LSUV initializing', layer.name)\n",
    "\n",
    "        layers_inintialized += 1\n",
    "        weights_and_biases = layer.get_weights()\n",
    "        weights_and_biases[0] = svd_orthonormal(weights_and_biases[0].shape)\n",
    "        layer.set_weights(weights_and_biases)\n",
    "        activations = get_activations(model, layer, batch)\n",
    "        variance = np.var(activations)\n",
    "        iteration = 0\n",
    "        if verbose:\n",
    "            print(variance)\n",
    "        while abs(needed_variance - variance) > margin:\n",
    "            if np.abs(np.sqrt(variance)) < 1e-7:\n",
    "                # avoid zero division\n",
    "                break\n",
    "\n",
    "            weights_and_biases = layer.get_weights()\n",
    "            weights_and_biases[0] /= np.sqrt(variance) / np.sqrt(needed_variance)\n",
    "            layer.set_weights(weights_and_biases)\n",
    "#             weights /= np.sqrt(variance) / np.sqrt(needed_variance)\n",
    "#             layer.set_weights([weights, biases])\n",
    "            activations = get_activations(model, layer, batch)\n",
    "            variance = np.var(activations)\n",
    "\n",
    "            iteration += 1\n",
    "            if verbose:\n",
    "                print(variance)\n",
    "            if iteration >= max_iter:\n",
    "                break\n",
    "    if verbose:\n",
    "        print('LSUV: total layers initialized', layers_inintialized)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T13:20:24.342733Z",
     "start_time": "2019-11-25T13:20:20.785490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.00000001, 0.        , 0.        , 0.        , 1.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model=load_model('pure_cnn_model_mnist_0-1.h5')\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# 归一化\n",
    "# x_train = x_train / 255.0\n",
    "# x_test = x_test / 255.0\n",
    "# #     x_train = preprocess_input(x_train,mode='tf')\n",
    "# #     x_test = preprocess_input(x_test,mode='tf')\n",
    "# # 标签激活\n",
    "# y_train = keras.utils.to_categorical(y_train, 10)\n",
    "# y_test = keras.utils.to_categorical(y_test, 10)\n",
    "# x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1], x_train.shape[2], 1))\n",
    "# x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1], x_test.shape[2], 1))\n",
    "aa=x_test[0,:,:,:]\n",
    "ww = aa.reshape((1,28,28,1))\n",
    "model=load_model('cifar_cnn_maxpool.h5')\n",
    "# model=load_model('./same_s7_k4_cnn.h5')\n",
    "# model=load_model('./same_s1_k3_cnn.h5')\n",
    "\n",
    "# pp = Image.open(\"./perturbed_image7.jpg\")\n",
    "# pp= np.reshape(pp,(1,784))\n",
    "# print(pp)\n",
    "model.predict(ww)\n",
    "# ww\n",
    "# ks = model.layers[1].get_weights()\n",
    "# w = ks[0]\n",
    "# b = ks[1]\n",
    "# print(w.shape,b.shape)\n",
    "# mykernel = w[:,:,0,0]\n",
    "# print(mykernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T16:31:26.963103Z",
     "start_time": "2020-01-09T16:31:19.824980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "conv2d_36\n",
      "dropout_13\n",
      "conv2d_37\n",
      "dropout_14\n",
      "flatten_13\n",
      "dense_25\n",
      "dropout_15\n",
      "dense_26\n",
      "(1, 10)\n",
      "[[0.0001558  0.00001518 0.00008591 0.9930757  0.00002154 0.00530663 0.00065563 0.00022137 0.00045099 0.00001113]]\n"
     ]
    }
   ],
   "source": [
    "model=load_model('cifar_valid_s2_k3_cnn.h5')\n",
    "t1,t2,x_test,y_test=preprocessing_data()\n",
    "for index,layer in enumerate(model.layers):\n",
    "    print(layer.name)\n",
    "intermediate_model = Model(inputs = model.input,outputs = model.get_layer('dense_26').output)\n",
    "out = intermediate_model.predict(np.reshape(x_test[0],(1,x_test[0].shape[0],x_test[0].shape[1], 3)))\n",
    "print(out.shape)\n",
    "# print(out[0,:,:,0])\n",
    "print(out)\n",
    "# print(model.predict(np.reshape(x_test[0],(1,x_test[0].shape[0],x_test[0].shape[1], 3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T02:44:55.499499Z",
     "start_time": "2019-10-15T02:44:55.493676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5325851838355151"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [[[0.42761427 ,0.42761427 ,0.42761427 ,0.42761427],\n",
    " [0.42761427 ,0.8159478  ,1.452899   ,0.53031933],\n",
    " [0.42761427 ,0.42761427 ,2.2135863  ,0.42761427],\n",
    " [0.42761427 ,0.67619896 ,0.13113204 ,0.42761427]],\n",
    "[[0.04829188 ,0.04829188 ,0.04829188 ,0.04829188],\n",
    " [0.04829188 ,2.6751187  ,2.6916704  ,0.851653  ],\n",
    " [0.04829188 ,0.04829188 ,2.6460803  ,0.04829188],\n",
    " [0.04829188 ,0.13802311 ,1.3577688  ,0.04829188]]]\n",
    "\n",
    "weights = np.array(weights)\n",
    "\n",
    "np.sum(weights[0]*mykernel)+b[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        272       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          8224      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               156900    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 166,406\n",
      "Trainable params: 166,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.2859 - acc: 0.9191\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0827 - acc: 0.9752\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0555 - acc: 0.9832\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0422 - acc: 0.9872\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0320 - acc: 0.9903\n",
      "10000/10000 [==============================] - 1s 119us/step\n",
      "LOSS: 0.03767170057085459 ACCU: 0.9877\n"
     ]
    }
   ],
   "source": [
    "def get_mnist_cnn():\n",
    "    batch_size = 128\n",
    "    nb_classes = 10  # 分类数\n",
    "    nb_epoch = 12  # 训练轮数\n",
    "    # 输入图片的维度\n",
    "    img_rows, img_cols = 28, 28\n",
    "    # 卷积滤镜的个数\n",
    "    nb_filters, nb_filters2 = 16, 32\n",
    "    pool_size = (2, 2)\n",
    "    kernel_size = (4, 4)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    stride = 2\n",
    "    strides = (stride, stride)\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "     # 归一化\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "#     x_train = preprocess_input(x_train,mode='tf')\n",
    "#     x_test = preprocess_input(x_test,mode='tf')\n",
    "    # 标签激活\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1], x_train.shape[2], 1))\n",
    "    x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1], x_test.shape[2], 1))\n",
    "\n",
    "    print(x_train.shape)\n",
    "    # 开始自定义组合神经网络结构\n",
    "#     mpadding = 'valid'\n",
    "    mpadding = 'same'\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters, kernel_size, strides=strides, padding=mpadding, activation='relu', input_shape=input_shape))\n",
    "#     model.add(MaxPooling2D())\n",
    "    model.add(Convolution2D(nb_filters2, kernel_size, strides=strides, padding=mpadding, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    # 拟合数据集，开始训练\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=5)\n",
    "#     model.fit(x_train,y_train,batch_size=batch_size,epochs=nb_epoch,validation_data=(x_test,y_test))\n",
    "\n",
    "    # 评估模型\n",
    "    score = model.evaluate(x_test,y_test)\n",
    "    print(\"LOSS:\",score[0],\"ACCU:\",score[1])\n",
    "#     return model\n",
    "    # 保存模型\n",
    "    model.save('pure_cnn_model_mnist_0-1.h5')\n",
    "get_mnist_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T16:16:06.093112Z",
     "start_time": "2019-11-11T16:15:32.775767Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mlp():\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    # 变成一维进行全连接层的网路训练\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    x_test = x_test.reshape(10000, 784)\n",
    "    # 归一化\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    # 标签激活\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    # 构建模型\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # 显示网络结构\n",
    "    model.summary()\n",
    "    # 编译\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # 拟合数据集，开始训练\n",
    "    model.fit(x_train,y_train,batch_size=64,epochs=30,validation_data=(x_test,y_test))\n",
    "    # 评估模型\n",
    "    score = model.evaluate(x_test,y_test)\n",
    "    print(\"LOSS:\",score[0],\"ACCU:\",score[1])\n",
    "    # 保存模型\n",
    "    model.save('fashion_mnist_model_2_24.h5')\n",
    "\n",
    "# get_mlp()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T16:18:49.918085Z",
     "start_time": "2019-11-11T16:18:13.264225Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# 变成一维进行全连接层的网路训练\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "# 归一化\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "# 标签激活\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model=load_model('fashion_mnist_model_2_24.h5')\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# 拟合数据集，开始训练\n",
    "model.fit(x_train,y_train,batch_size=64,epochs=30,validation_data=(x_test,y_test))\n",
    "# 评估模型\n",
    "score = model.evaluate(x_test,y_test)\n",
    "print(\"LOSS:\",score[0],\"ACCU:\",score[1])\n",
    "model.save('fashion_mnist_model_2_24.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T09:13:43.154480Z",
     "start_time": "2020-01-03T09:07:37.989960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               204900    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 222,566\n",
      "Trainable params: 222,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "conv2d_9\n",
      "LSUV initializing conv2d_9\n",
      "0.0077623436\n",
      "0.9999998\n",
      "conv2d_10\n",
      "LSUV initializing conv2d_10\n",
      "0.055105504\n",
      "1.0000005\n",
      "max_pooling2d_5\n",
      "conv2d_11\n",
      "LSUV initializing conv2d_11\n",
      "0.047631327\n",
      "0.9999996\n",
      "conv2d_12\n",
      "LSUV initializing conv2d_12\n",
      "0.048417572\n",
      "0.9999997\n",
      "max_pooling2d_6\n",
      "flatten_1\n",
      "dense_1\n",
      "LSUV initializing dense_1\n",
      "0.84689975\n",
      "0.99999994\n",
      "dropout_1\n",
      "dense_2\n",
      "dense_2 too small\n",
      "LSUV: total layers initialized 5\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 1.9253 - acc: 0.3012 - val_loss: 1.6060 - val_acc: 0.4360\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.5969 - acc: 0.4265 - val_loss: 1.4335 - val_acc: 0.4980\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.4547 - acc: 0.4789 - val_loss: 1.3425 - val_acc: 0.5262\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.3632 - acc: 0.5120 - val_loss: 1.2707 - val_acc: 0.5535\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.2902 - acc: 0.5417 - val_loss: 1.2193 - val_acc: 0.5725\n",
      "10000/10000 [==============================] - ETA:  - 3s 319us/step\n",
      "LOSS: 1.2192756740570068 ACCU: 0.5725\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocessing_data():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    print(x_train.shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "     # 归一化\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "#     x_train = preprocess_input(x_train,mode='torch')\n",
    "#     x_test = preprocess_input(x_test,mode='torch')\n",
    "#     x_train = preprocess_input(x_train,mode='tf')\n",
    "#     x_test = preprocess_input(x_test,mode='tf')\n",
    "    # 标签激活\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def get_cifar_cnn():\n",
    "    x_train, y_train, x_test, y_test = preprocessing_data()\n",
    "    batch_size = 128\n",
    "    nb_classes = 10\n",
    "    nb_epoch = 5\n",
    "    img_rows, img_cols, img_channels = x_train.shape[1], x_train.shape[2], x_train.shape[3]\n",
    "    nb_filters, nb_filters2 = 16, 32\n",
    "    pool_size = (2, 2)\n",
    "    kernel_size = (3, 3)\n",
    "    input_shape = (img_rows, img_cols, img_channels)\n",
    "    stride = 1\n",
    "    strides = (stride, stride)\n",
    "#     mpadding = 'valid'\n",
    "    mpadding = 'same'\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters, kernel_size, strides=strides, padding=mpadding, activation='relu', input_shape=input_shape))\n",
    "    model.add(Convolution2D(nb_filters, kernel_size, strides=strides, padding=mpadding, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Convolution2D(nb_filters2, kernel_size, strides=strides, padding=mpadding, activation='relu'))\n",
    "    model.add(Convolution2D(nb_filters2, kernel_size, strides=strides, padding=mpadding, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model = LSUVinit(model,x_train[:batch_size,:,:,:])\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, validation_data=(x_test,y_test), shuffle=True)\n",
    "    score = model.evaluate(x_test,y_test)\n",
    "    print(\"LOSS:\",score[0],\"ACCU:\",score[1])\n",
    "    model.save('cifar_cnn_maxpool.h5')\n",
    "    \n",
    "get_cifar_cnn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T12:31:19.445662Z",
     "start_time": "2019-11-11T12:29:57.623726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.7455 - acc: 0.3689 - val_loss: 1.7281 - val_acc: 0.3737\n",
      "Epoch 2/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7417 - acc: 0.3709 - val_loss: 1.7367 - val_acc: 0.3675\n",
      "Epoch 3/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7387 - acc: 0.3723 - val_loss: 1.7413 - val_acc: 0.3658\n",
      "Epoch 4/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7386 - acc: 0.3708 - val_loss: 1.7415 - val_acc: 0.3643\n",
      "Epoch 5/60\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 1.7355 - acc: 0.3728 - val_loss: 1.7303 - val_acc: 0.3688\n",
      "Epoch 6/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7362 - acc: 0.3714 - val_loss: 1.7405 - val_acc: 0.3664\n",
      "Epoch 7/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7393 - acc: 0.3721 - val_loss: 1.7502 - val_acc: 0.3628\n",
      "Epoch 8/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7385 - acc: 0.3715 - val_loss: 1.7502 - val_acc: 0.3643\n",
      "Epoch 9/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7338 - acc: 0.3736 - val_loss: 1.7328 - val_acc: 0.3735\n",
      "Epoch 10/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7345 - acc: 0.3747 - val_loss: 1.7436 - val_acc: 0.3607\n",
      "Epoch 11/60\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.7318 - acc: 0.3743 - val_loss: 1.7335 - val_acc: 0.3710\n",
      "Epoch 12/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7320 - acc: 0.3745 - val_loss: 1.7466 - val_acc: 0.3636\n",
      "Epoch 13/60\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.7287 - acc: 0.3750 - val_loss: 1.7731 - val_acc: 0.3545\n",
      "Epoch 14/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7354 - acc: 0.3730 - val_loss: 1.7560 - val_acc: 0.3632\n",
      "Epoch 15/60\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 1.7290 - acc: 0.3732 - val_loss: 1.7259 - val_acc: 0.3721\n",
      "Epoch 16/60\n",
      "50000/50000 [==============================] - 1s 28us/step - loss: 1.7257 - acc: 0.3756 - val_loss: 1.7511 - val_acc: 0.3644\n",
      "Epoch 17/60\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.7251 - acc: 0.3772 - val_loss: 1.7253 - val_acc: 0.3720\n",
      "Epoch 18/60\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.7250 - acc: 0.3768 - val_loss: 1.7437 - val_acc: 0.3691\n",
      "Epoch 19/60\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.7298 - acc: 0.3729 - val_loss: 1.7398 - val_acc: 0.3666\n",
      "Epoch 20/60\n",
      "50000/50000 [==============================] - 1s 29us/step - loss: 1.7233 - acc: 0.3763 - val_loss: 1.7287 - val_acc: 0.3741\n",
      "Epoch 21/60\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.7222 - acc: 0.3765 - val_loss: 1.7343 - val_acc: 0.3674\n",
      "Epoch 22/60\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.7250 - acc: 0.3773 - val_loss: 1.7509 - val_acc: 0.3626\n",
      "Epoch 23/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7248 - acc: 0.3781 - val_loss: 1.7495 - val_acc: 0.3685\n",
      "Epoch 24/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7223 - acc: 0.3787 - val_loss: 1.7439 - val_acc: 0.3650\n",
      "Epoch 25/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7247 - acc: 0.3764 - val_loss: 1.7287 - val_acc: 0.3704\n",
      "Epoch 26/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7194 - acc: 0.3808 - val_loss: 1.7508 - val_acc: 0.3717\n",
      "Epoch 27/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7224 - acc: 0.3785 - val_loss: 1.7552 - val_acc: 0.3605\n",
      "Epoch 28/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7198 - acc: 0.3788 - val_loss: 1.7449 - val_acc: 0.3683\n",
      "Epoch 29/60\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.7162 - acc: 0.3796 - val_loss: 1.7223 - val_acc: 0.3733\n",
      "Epoch 30/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7189 - acc: 0.3795 - val_loss: 1.7309 - val_acc: 0.3748\n",
      "Epoch 31/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7165 - acc: 0.3801 - val_loss: 1.7385 - val_acc: 0.3701\n",
      "Epoch 32/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7209 - acc: 0.3786 - val_loss: 1.7214 - val_acc: 0.3748\n",
      "Epoch 33/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7200 - acc: 0.3784 - val_loss: 1.7648 - val_acc: 0.3639\n",
      "Epoch 34/60\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.7183 - acc: 0.3784 - val_loss: 1.7279 - val_acc: 0.3716\n",
      "Epoch 35/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7145 - acc: 0.3809 - val_loss: 1.7408 - val_acc: 0.3679\n",
      "Epoch 36/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7167 - acc: 0.3789 - val_loss: 1.7216 - val_acc: 0.3738\n",
      "Epoch 37/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7140 - acc: 0.3814 - val_loss: 1.7427 - val_acc: 0.3724\n",
      "Epoch 38/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7142 - acc: 0.3809 - val_loss: 1.7409 - val_acc: 0.3658\n",
      "Epoch 39/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7137 - acc: 0.3816 - val_loss: 1.7284 - val_acc: 0.3706\n",
      "Epoch 40/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7148 - acc: 0.3822 - val_loss: 1.7279 - val_acc: 0.3712\n",
      "Epoch 41/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7126 - acc: 0.3787 - val_loss: 1.7244 - val_acc: 0.3775\n",
      "Epoch 42/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7122 - acc: 0.3813 - val_loss: 1.7201 - val_acc: 0.3805\n",
      "Epoch 43/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7116 - acc: 0.3800 - val_loss: 1.7308 - val_acc: 0.3689\n",
      "Epoch 44/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7077 - acc: 0.3807 - val_loss: 1.7174 - val_acc: 0.3781\n",
      "Epoch 45/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7107 - acc: 0.3806 - val_loss: 1.7296 - val_acc: 0.3743\n",
      "Epoch 46/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7134 - acc: 0.3789 - val_loss: 1.7227 - val_acc: 0.3731\n",
      "Epoch 47/60\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.7101 - acc: 0.3828 - val_loss: 1.7286 - val_acc: 0.3751\n",
      "Epoch 48/60\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.7088 - acc: 0.3842 - val_loss: 1.7193 - val_acc: 0.3776\n",
      "Epoch 49/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7089 - acc: 0.3819 - val_loss: 1.7188 - val_acc: 0.3769\n",
      "Epoch 50/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7061 - acc: 0.3858 - val_loss: 1.7448 - val_acc: 0.3680\n",
      "Epoch 51/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7086 - acc: 0.3815 - val_loss: 1.7239 - val_acc: 0.3761\n",
      "Epoch 52/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7092 - acc: 0.3835 - val_loss: 1.7356 - val_acc: 0.3682\n",
      "Epoch 53/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7059 - acc: 0.3846 - val_loss: 1.7150 - val_acc: 0.3765\n",
      "Epoch 54/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7051 - acc: 0.3841 - val_loss: 1.7262 - val_acc: 0.3792\n",
      "Epoch 55/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7059 - acc: 0.3830 - val_loss: 1.7380 - val_acc: 0.3730\n",
      "Epoch 56/60\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.7076 - acc: 0.3837 - val_loss: 1.7783 - val_acc: 0.3550\n",
      "Epoch 57/60\n",
      "50000/50000 [==============================] - 1s 25us/step - loss: 1.7059 - acc: 0.3831 - val_loss: 1.7275 - val_acc: 0.3734\n",
      "Epoch 58/60\n",
      "50000/50000 [==============================] - 1s 26us/step - loss: 1.7063 - acc: 0.3838 - val_loss: 1.7356 - val_acc: 0.3710\n",
      "Epoch 59/60\n",
      "50000/50000 [==============================] - 1s 27us/step - loss: 1.7027 - acc: 0.3846 - val_loss: 1.7569 - val_acc: 0.3568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/60\n",
      "50000/50000 [==============================] - 1s 24us/step - loss: 1.7030 - acc: 0.3839 - val_loss: 1.7250 - val_acc: 0.3760\n",
      "10000/10000 [==============================] - 0s 20us/step\n",
      "LOSS: 1.7250324214935302 ACCU: 0.376\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = preprocessing_data()\n",
    "# 变成一维进行全连接层的网路训练\n",
    "x_train = x_train.reshape(50000, 32*32*3)\n",
    "x_test = x_test.reshape(10000, 32*32*3)\n",
    "model = load_model('cifar_model_3_24.h5')\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# 拟合数据集，开始训练\n",
    "model.fit(x_train,y_train,batch_size=128,epochs=60,validation_data=(x_test,y_test))\n",
    "# 评估模型\n",
    "score = model.evaluate(x_test,y_test)\n",
    "print(\"LOSS:\",score[0],\"ACCU:\",score[1])\n",
    "model.save('cifar_model_3_24.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T02:51:41.891696Z",
     "start_time": "2019-10-27T02:51:41.669560Z"
    }
   },
   "outputs": [],
   "source": [
    "# eran测试数据集文本写出\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train = x_train.reshape(60000, 784)\n",
    "# print(x_test[0])\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "\n",
    "test_imgs = []\n",
    "import copy\n",
    "with open('mytestdataset.csv', 'w') as fs:\n",
    "    for i in range(100):\n",
    "        arr = copy.copy(x_test[i].tolist())\n",
    "        arr.insert(0,y_test[i])\n",
    "        arr = [str(x) for x in arr]\n",
    "#         test_imgs.append(','.join(arr))\n",
    "        fs.write(','.join(arr)+'\\n')\n",
    "# df = pd.DataFrame(test_imgs)\n",
    "\n",
    "# df = df.append(,ignore_index=True)\n",
    "# df.to_csv('mytestdataset.csv',index=False, header=False)\n",
    "\n",
    "# print(arr)\n",
    "# print([y_test[0]]+x_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T10:59:20.366318Z",
     "start_time": "2019-12-22T10:59:20.060339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10777f978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHypJREFUeJztnWuMnOd13/9n3rns/cYll8urKImyIqsxpdCqnaiK7NSBoiSQDQSuXcBQASMKigiogfSD4AK1C/SDU9Q2/KFwQVeqFcO1rNoWJCRCalsOIhh2JFE36kJdKF4kkksuyeXed3Zupx9mZFCr5/9wyCVnqTz/H0Bw9jnzvO+Z933PvDPPf8455u4QQqRHbq0dEEKsDQp+IRJFwS9Eoij4hUgUBb8QiaLgFyJRFPxCJIqCX4hEUfALkSj51Uw2szsAfAtABuB/ufvXYs/v7877uoFieFvx/Vywb7FfLjq4LbovMi26Pb61uNFj78sx/8M2i+2MzAGA2A9AL+7XodyP2NbcL/waaG6THQ9OI/qiL86P2KtjlkbEDebjzEINS8v1tpy86OA3swzA/wDwKQBHATxjZo+5+6tszrqBIr7yb68Pb88bdF/FQthNy/EAqVSWqa1Wr/J9FcNvTgBQb4R99MhZslyd2nIZNcGrvXyb4NssFMvB8Sxyqi3H/a83atRWrfFz1miQ68+4H7XINbvMtofzBXLYx9ibfKXCr496PXIcI9dwLnLOKuS6WuCHHouV8Pa+9/NjfNL7fLp4bgFwwN0PunsFwEMA7lrF9oQQHWQ1wb8ZwDvn/H20NSaE+ABw2Rf8zOweM9trZnvnlyKfY4QQHWU1wX8MwNZz/t7SGnsP7r7H3Xe7++6+7lWtLwohLiGrCf5nAOw0sx1mVgTwOQCPXRq3hBCXm4u+Fbt7zczuBfD/0JT6HnD3V6JzYKiQ9xv3JT6RrIaWwFfEc+BL6fl8ZAX+IhQ2K/BJy5UKtdUaER8jUl8WUQnyZJo1+Ao2alwZia1SNyL+V6wrOF7PSnxObHt1fjyswX00olZ0Rc5Z3rgtl48oI9XIMTb+ldfJMfaIjpFlYR8vRIhc1edwd38cwOOr2YYQYm3QL/yESBQFvxCJouAXIlEU/EIkioJfiETp8K9uHM4SRZzLTV4Pz7E6l4YaVS6xZd0R2Qg8OYNJbI2I1FQsFKit5tzWqEZeW2R/tVrYZpFMtVxEVrSMJzp5FpbzAGCpHpb0TpzhcthChfs4P8/nZc6PR39X+DgWjZ/ngZ5uausuccmukePXXC4q24V95FcHUGXJZBeg9enOL0SiKPiFSBQFvxCJouAXIlEU/EIkSkdX+80d+TpZ1c8iq9EkKaWUReoD5CPLnpHsnRxJmABAE3tqsWJrOe5HochXlTdedR21zU6fprbTZxbD+8rzVfscIsk2NX6JLDn3f/+RsI9eGqFzqhlP1Kr0cWVhfmaK2o5NTgfH+0r8ddVPhOcAwLYxfhzX9fPj2JWPlf8KX8fFyCVcJwrHhdS71J1fiERR8AuRKAp+IRJFwS9Eoij4hUgUBb8QibIG5XTDUoTlh/gMIl/UYh1SclwGrNR4AkYxUmOuXie11iKJNohIL8VIHbl/+a8/RW3P/urX1HZ8+kxwfCEi2dXqXGI7cvQUtR06xrvDlIbGg+NbxnbQOV7qp7ZKnp+XQt96aquV54PjZyaP0zk9Q1yOPDp/ktrKpNYkAIz18zSdnkI4sadeDcu2AMCaLEU6r71/G+0/VQjxzwkFvxCJouAXIlEU/EIkioJfiERR8AuRKKuS+szsMIA5AHUANXffHXt+w3JYzoXlnJnFHjqvTtpJDfdxOW8g4/JbPlLPrhGRAZmMQusSIp4luLh4ltp+8bePUtvJaV7v8OR8eH9HjvF9HZl4h9qyrj5qq2cD1NY7MBocL/Tw7eW7eJZgKdJCqyvHpcrTlXAbuPEt2+ic8tICtR06xKW+qZkytWXGX/dV68O2Qp1Lh8bqWl5AVt+l0Pk/4e48x1QIcUWij/1CJMpqg98B/NTMnjWzey6FQ0KIzrDaj/23uvsxM9sA4Gdm9pq7P3nuE1pvCvcAwHA/r4IihOgsq7rzu/ux1v+TAB4BcEvgOXvcfbe77+7rXoNUAiFEkIsOfjPrNbP+dx8D+EMAL18qx4QQl5fV3IrHADzSkhbyAP6Pu/99bEKtYTi1FM5gmqryrL4nf/WPwfHf2sklnk98OCw1AcBwpFhog2TuAUCOtFXK5XjGVt15m6mIeoVDRw5R29QSz3DznuHgeNbHpabc8By1dQ8NUlulzKWtCmmHNTDMz9lAH7dNnjhBbbNneQHP/mL4Eu/q5rLi22e5eFXo30Btp068TW19J/kx3jgQ9qXbIpmYpKgtIjL2Si46+N39IICPXOx8IcTaIqlPiERR8AuRKAp+IRJFwS9Eoij4hUiUzvbqy0rID4YLOC6e4e9D1WK4QOPUYlh6A4DFCu/tNlDkmXsN0jetZQwOZxnPSCxXuKR0iifn4fQclxxjBSaH14ez1RYas3TOKLiPWSTTrlLgx7G8EJa2yvPcj+1j66htkUh2ADBJMvcAwAphWXRmihfHRKQg69ICz/jLivw6mJzlWZUTJBtw+yi/vnMs4a/9pD7d+YVIFQW/EImi4BciURT8QiSKgl+IROnoan9Xdy8+9Nvvy/oFABz9p9fpvL7B8Gr/LR8PbwsAerIj1FYhK9EAkMvzJB0rhFe+686Tkvo3bKW2F/YdoLa+Ib7yvXn7h6nNc+HV7UJkZb6xHG7xBQCVSqQlWuRYZSQp5ZUX99E5A6VIS6tenvTTG6kLePxEuOZejSg3AJARhQAAhvu5+jFT50lcZ6e47dCJmeD4prGNdE6eKVaxbLEV6M4vRKIo+IVIFAW/EImi4BciURT8QiSKgl+IROmo1JfL8ugZDEtY26++js5bIirJth3X0jmjVS7lTB/iMmA1kthTr4UTN2657dN0zrareQezHf/iMLU9+/yL1DbcxyWg45Ph+nN552XTSwUusSFSEm4+kuQyQ+rqDffyfcWqz9Uj0tzo+rAUDADL1fD5PH02LK8BgEVarPVH6gzmMx5OlTJPJDr4ztHg+PohLivu3BJue+cXcD/XnV+IRFHwC5EoCn4hEkXBL0SiKPiFSBQFvxCJcl6pz8weAPAnACbd/cbW2AiAHwK4CsBhAJ91d16k7N1t5XLISuEMrOMn99N5u37no8Hx3kFeMy2bO0Zt9RqXjfKRWnEH3wlnA946HK5LCADo2UJN/b1c/unK80y17kituK4iyUiL1KXbvGmc2l596y1qKxZ5ncTZufCxumrLTjrnuutvoLapKX559Q3wrMrjJyaD45bj9fGGhnmNxJlILb4sIhF293Afl+bC18EBcr0BQHcxvK9qjWdhrqSdO/93AdyxYuw+AE+4+04AT7T+FkJ8gDhv8Lv7kwBW/mLjLgAPth4/CID/ykUIcUVysd/5x9x9ovX4BJode4UQHyBWveDn7o7ILzPN7B4z22tme2dmeM12IURnudjgP2lm4wDQ+j+8qgLA3fe4+2533z04OHCRuxNCXGouNvgfA3B36/HdAB69NO4IITpFO1LfDwDcDmDUzI4C+AqArwF42My+COAIgM+2szOzDIWu8N2/XOYFJpeXw2l9hYjk1dPLP2X0RlpQlTKe1deXD/fX+u6e++mcP/0391JbYeEEtRVL/H05l+M+7rh6c3B8cuo4nVOe59l5GzeMUtvULJcqlyvh83n1tTwT85preWbnzPPPUdvC3Dy1zS6EfazVuSS2tBRunwUAQ0OD1FZ3Ls0NDPFsxlolfD6zHO/ndnQi/GG7QrIYQ5w3+N3988T0B23vRQhxxaFf+AmRKAp+IRJFwS9Eoij4hUgUBb8QidLRAp4wg2VhyWMxIjeVF5eC44VIT7W5MzyLDRmX+grghR3Hh8KZYG/u5z33jh/lNixy+e3I0cPUdtNG3qNw8/Zwcc9Nk/wX2AsHeEHTkVKkD+EQlwEPHjwcHB/fFJYiAWB6lv8CtBqR5k6e4r0GG27BcYsU21yMSH2W49dVeE9NeiOFP9EIZxEWLXzdA0DlTFgm9mgZ1PeiO78QiaLgFyJRFPxCJIqCX4hEUfALkSgKfiESpbNSnwMgPdcy51LO+Gi4v19PF5f6frGPF54cjhQ53DnCs6+6SmGZp5jn0tCpycPU1ljmxSC3XcOLgmaR190zMBwcHx3jhUTPTPGsuJlI5l49oqauJ/3z8hF5tkyy24B4ttpSmWe/1YiTbBwAyss8w7RW4/fLdaMbqM2MX1dFC18/JYv0jfRwRmshUkR0JbrzC5EoCn4hEkXBL0SiKPiFSBQFvxCJ0tHVfjOgkA8nxwz28WSbof6wzRp8NXTWeSLF6bM8BWO0nx+S3mJ4xbaeC9cYBIDDxw9T29gwrwe3/VreuqrMd4ennw23PTs2wZWF/r6wQgAAhQJvyfXKgbe5I+S+0ojcb5Yjq/3zCzzJZWiEt9eqkcSeiZO04DR6+/l5yWc8caanh9eULLI2agBQDScm1Rem6ZSxDf3B8XyBtyFbie78QiSKgl+IRFHwC5EoCn4hEkXBL0SiKPiFSJR22nU9AOBPAEy6+42tsa8C+HMAp1pP+7K7P97ODjMLSy8bN4RrzzWdJLJRJKFjfAtPjNkbkd+mjUuEnoXrDA6O8iSRwQGe0FHoCss1AHBVROrrGwwnOgHA/37ge8Hxxcixml2aorbFJV5bsRC5ejYOh193eYrXC1wgiVMAMDjAz8trr79JbSdPngqOz0ZafA0N8Rc20NtHbZlzDbZQ4ccxI7Uc1/fy7Q12heMofwG383ae+l0AdwTGv+nuu1r/2gp8IcSVw3mD392fBMBvDUKIDySr+c5/r5ntM7MHzIz/REwIcUVyscH/bQDXANgFYALA19kTzeweM9trZnunp/nPFYUQneWigt/dT7p73d0bAL4DgHaRcPc97r7b3XcPDfEGEEKIznJRwW9m4+f8+RkAL18ad4QQnaIdqe8HAG4HMGpmRwF8BcDtZrYLzap8hwH8RTs7y+VyNLtpYJhLfbV62M1SnmdKXbdjG7XtfZZLbLOFa6mtYXPB8bHNXM57df8/Udvv/v6/o7Zf/4rPW1iItLWqnA6OT554h86J3QPmq9yWB5eihnPhLMLN3dz3mVNcsqtlfFlpbAO31evhTMGlSEuu8hKvW7gQqUFYa3D5sFo+Rm0bCuGMxU19PEtwuRaecyF38/MGv7t/PjB8/wXsQwhxBaJf+AmRKAp+IRJFwS9Eoij4hUgUBb8QidLRAp65XA69feHsrOHRUTqvZmE3y7kindPVN0BtQ0O8QOPb75ygtls/+uGwH/O8/VdPfzirDAAmjh2ltgNvvEFttTpvJ5Uj9RsXZmfonP5149Q2M8Nlr8E+XtzzQ9fdGBx/5sXX6JznXjtMbbfe/kfUVihySezggQPB8Zk5/rpiRUbLS1zO2z7GJeTuXl6gdmQkPM/zvKBprRIuJOokazaE7vxCJIqCX4hEUfALkSgKfiESRcEvRKIo+IVIlI5Kfe4NNGphiWVwhBdGXFgKF3ZcrPO+aVnG39e2bd1CbW+8wjPLZhbDkl5fL88g3HoNNeHIG7yY5bHjE9T28Y9/lNoWF8NSVP+mzXTOyCZe7PTtKS7NLS1zibPYG+6fN7B+K51zUz8/L6dOhfvZAcDhIy9S28JSWBadnuGS3fr166lt0Pl52d7HJdgNA7yHXsHCmY6VKu9P2EskvRx4TLz/uUKIJFHwC5EoCn4hEkXBL0SiKPiFSJSOrvY3alXMnQmvlnZHaqMtl8OrqNbg7pvxVc/REd7u6o3cQWqbnAq3XDqT8VXvwT5em/D6G3mC0cEjvOZelXe1wvRsWE3ZuXMnnbNzB5ckjkzwhKBXXnmJ2s6cDifbFEtc1Rnu44kxR1/hqsOJM7wuoJHkryzSKi3W6m17JG9mWz9PdOrK8SSd5XL4+mk0eG3Iao1sr/3Fft35hUgVBb8QiaLgFyJRFPxCJIqCX4hEUfALkSjttOvaCuBvAIyhKSTscfdvmdkIgB8CuArNll2fdfdwj6YWy8vLOHggLKVt2/lbdF5XLiz1NSo88SHfFZFdIrb+fi5F9Q2E6wJef/2H6Jyf//Rxaluc4fUCe0Y2UNuBo5PUtnVLOMlox4dupnNKRX4ZXL2NJy1NT/HT/er+cIJUw7lOeWyaJ8bMkuQuACjXuUw8Ox2WPjds5ElEb5/h9f1GtnJ59kyJ+4EGf23TtfBr8zy/TpfJ9irgCUQraefOXwPwV+5+A4CPAfhLM7sBwH0AnnD3nQCeaP0thPiAcN7gd/cJd3+u9XgOwH4AmwHcBeDB1tMeBPDpy+WkEOLSc0Hf+c3sKgA3AXgKwJj7b5KbT6D5tUAI8QGh7eA3sz4APwbwJXd/z+8p3d1BflhoZveY2V4z2zs3xwsoCCE6S1vBb2YFNAP/++7+k9bwSTMbb9nHAQRXodx9j7vvdvfdscU0IURnOW/wm5kBuB/Afnf/xjmmxwDc3Xp8N4BHL717QojLRTtZfb8H4AsAXjKzF1pjXwbwNQAPm9kXARwB8NnzbWhxuYYXDoRlqm033kLnNRDOpjOW2QQADZ7eNDs3R23T06epbd3IruD4nXd8gs7Z9ZHrqe3hnzxCbWZcshkcHKa2zZvCElbfwBCdk9XCxxcARjbyS2R8R5XaZrrDMtXzL/J6exPzPGXOC7z92uBGnqU5ek1YmssiMlrduR+ve7jdHAAcOMHlyGLGt7lULgfHFyOXd60Rvj7m6jz7cSXnDX53/yUA5vkftL0nIcQVhX7hJ0SiKPiFSBQFvxCJouAXIlEU/EIkSkcLeJbrhjdmuoO203VeUNELYSkkV+HFJZ1IIQCQy3HbpnGeTfevfjecGddV4BLPju28TdYf/9nnqO1Hj/wdtZ0+wV/3xEy4GGS5fIDOKYJrSlNL3HbgCM9KRCUsA/ooz4Ac3hAu+gkAjUhlyuZv0Mi8rvA2GxYu7AkA1UgbuJk631dXgW+zK8+lvgULZxFWC3xf3ggf33pEIl6J7vxCJIqCX4hEUfALkSgKfiESRcEvRKIo+IVIlI5Kfct1wxvT4febR3/J+77t2j4aHN9Y5BlWPYVINtpG3j9vfJRnj11zNSn66Lw448SpM9T2wENcznvuhVepjfUuBACa6Oj8fd7rfHv1Ej8e9RyXovIIS7q1iBRVy4XnAEBX7EqNZOGVK+HX7Tk+Jx/J+MsavC+jl7ksWgOfV2iEfcyMn7NKNex/pEXl+9CdX4hEUfALkSgKfiESRcEvRKIo+IVIlI6u9tdhmM+Fkx+eeO4NOu/Nt8Itvu74nRvonGs28bZKhw6GW0kBwG0fvZHaukiixVyFr2A//PfPUNvzrx6ntsVapPVTZDU6Vwi/nzciNQ1zxlepY6vi9QZPaFomK9jVOp9jxmsCLiOS5OL8teXzZCU94/e9nh6eoFME97/OF/RRNx5qdTKxVuXnpdgfrsloufZDWnd+IRJFwS9Eoij4hUgUBb8QiaLgFyJRFPxCJMp5dQEz2wrgb9Bswe0A9rj7t8zsqwD+HMCp1lO/7O6PR3eWz2Pd6Pqgbeosl2smzk4Hx3/1Im9NVK9uj3jCpZz1G0nyDgDLwvLb03tfpnP+7he/prblBq9ZhzyX+nK5C3/Pri/z5B2PyICNiJwXk9hYy6tCnl9ylkXqz2X8nOUj87IsvL9Y09gscnxzzuXIeiR5qhGRKplGuHEjl6v7B8K2t0r8OK2kHVGwBuCv3P05M+sH8KyZ/axl+6a7//e29yaEuGJop1ffBICJ1uM5M9sPgJekFUJ8ILigz49mdhWAmwA81Rq618z2mdkDZsZbxwohrjjaDn4z6wPwYwBfcvdZAN8GcA2AXWh+Mvg6mXePme01s721Jd4aWwjRWdoKfmt2RfgxgO+7+08AwN1Punvd3RsAvgPgltBcd9/j7rvdfXe+mzfmEEJ0lvMGv5kZgPsB7Hf3b5wzPn7O0z4DgC95CyGuONpZ7f89AF8A8JKZvdAa+zKAz5vZLjTlv8MA/uJ8GzIzKssUClzaqpXD8sXhk7N0zvLCfmq77ebrqK17aJzaZsphSeYfn9pL55SdZ2ZVa1w2KpV45l4jUkducTHc+ilGFsk4M57Uh0gHLZSIxBbNOovYrMRl0e5uXvsvT6TFaiRjbm5hgdrqEVl0ucbPy+BwuA4lAIyNh219kcKFS3Phr9AeuTZW0s5q/y8BhC6BqKYvhLiy0S/8hEgUBb8QiaLgFyJRFPxCJIqCX4hE6WgBT7ijUSNZYrGMqCwse1XAs7km55ep7bnXeeHMOxe5lDPnYXnl2Fn+y8VSH88eqy1y/8vL3P+enoi0RdqUxbZnOe5HLtJeK5ah50S288j9phCRN+erPLuwUuPSHJMBYxmJMcluIdIqrW+Iy3lD63mLuEotvM3XX+NZqwWSbVmtcP9Woju/EImi4BciURT8QiSKgl+IRFHwC5EoCn4hEqXDUh8AlhXlXF7JsnDxw4ZzGaqe4wUTD09yae6Bh3m+0idv3x0cP3T8VHAcABbrsaKOEdmrixdizIrc1kN60BW7uYy2NMelslj2m0cksQLJSMvy/JzF9pVFinTG+hAuLc5f8JzYvoaGR6ht3RjPCD19Zorapk+fCI+/zXtKXrtjR9gQkTBXoju/EImi4BciURT8QiSKgl+IRFHwC5EoCn4hEqWjUl+WzzAyNBS0lctcfltYCmcqFTOe3VaLyFC5SLHQJ5/eR22HjoezAWcWeCHOqfklaiPJXACA3t5INmCkSGOpFH5t+Yg82NXNM+aySMZfvsC3WSf3lVpEYrOIzZ37WK/y41+phg9ydxeXPkfXraO24VEu51UimanLxUgxTtJfr5HncvVCOXxdNSKS+Up05xciURT8QiSKgl+IRFHwC5EoCn4hEuW8q/1m1gXgSQCl1vN/5O5fMbMdAB4CsA7AswC+4O7RAmLecCyTVcpS5G1ouR5ezS1kfLW5xhep4Tm+s1w3X2U/QhJ4cpFklVqVr2DHFIlyuUxtC5F2Ujny2pgKAAC9Rb6q3B1JCMrluP/FrvD+unv48a1UeGLP6SmeGNMAn5cvhI/H8EAvnTM2ElakAGDjRp7YM73A6yTOTZ+ltvmZ6eD40Ajf1+lTp4PjtUhy1EraufMvA/iku38EzXbcd5jZxwD8NYBvuvu1AM4C+GLbexVCrDnnDX5v8m5eZKH1zwF8EsCPWuMPAvj0ZfFQCHFZaOs7v5llrQ69kwB+BuAtANPuv2lBexTA5svjohDictBW8Lt73d13AdgC4BYA17e7AzO7x8z2mtne6iJvqS2E6CwXtNrv7tMA/gHAxwEMmf2msfsWAMfInD3uvtvddxd6BlblrBDi0nHe4Dez9WY21HrcDeBTAPaj+SbwZ62n3Q3g0cvlpBDi0tNOYs84gAfNLEPzzeJhd/9bM3sVwENm9l8BPA/g/vNtqNFoYHkpLGGVMqPzeoiXjSpPmol0mUIDXKKKJUY0SHuwWiWSkFLnryvWMipma0QSe5jUd/Ysl5qmIsdxoI9LYoORenYDpJZgF7h0WG9wqSxvkeSjEj/Zy+XwNkt5fl5i+6otzkRs3P/56TPU1iDJR10lLsGWWZ1B469rJecNfnffB+CmwPhBNL//CyE+gOgXfkIkioJfiERR8AuRKAp+IRJFwS9EolhMUrrkOzM7BeBI689RAOHUpM4iP96L/HgvHzQ/trv7+nY22NHgf8+Ozfa6e7j5nfyQH/Ljsvuhj/1CJIqCX4hEWcvg37OG+z4X+fFe5Md7+Wfrx5p95xdCrC362C9EoqxJ8JvZHWb2upkdMLP71sKHlh+HzewlM3vBzPZ2cL8PmNmkmb18ztiImf3MzN5s/T+8Rn581cyOtY7JC2Z2Zwf82Gpm/2Bmr5rZK2b2H1rjHT0mET86ekzMrMvMnjazF1t+/JfW+A4ze6oVNz80M17Bth3cvaP/AGRolgG7GkARwIsAbui0Hy1fDgMYXYP93gbgZgAvnzP23wDc13p8H4C/XiM/vgrgP3b4eIwDuLn1uB/AGwBu6PQxifjR0WMCwAD0tR4XADwF4GMAHgbwudb4/wTw71ezn7W4898C4IC7H/Rmqe+HANy1Bn6sGe7+JICVtajvQrMQKtChgqjEj47j7hPu/lzr8RyaxWI2o8PHJOJHR/Eml71o7loE/2YA75zz91oW/3QAPzWzZ83snjXy4V3G3H2i9fgEgLE19OVeM9vX+lpw2b9+nIuZXYVm/YinsIbHZIUfQIePSSeK5qa+4Heru98M4I8A/KWZ3bbWDgHNd34035jWgm8DuAbNHg0TAL7eqR2bWR+AHwP4kru/p9prJ49JwI+OHxNfRdHcdlmL4D8GYOs5f9Pin5cbdz/W+n8SwCNY28pEJ81sHABa/0+uhRPufrJ14TUAfAcdOiZmVkAz4L7v7j9pDXf8mIT8WKtj0tr3BRfNbZe1CP5nAOxsrVwWAXwOwGOddsLMes2s/93HAP4QwMvxWZeVx9AshAqsYUHUd4OtxWfQgWNiZoZmDcj97v6Nc0wdPSbMj04fk44Vze3UCuaK1cw70VxJfQvAf1ojH65GU2l4EcArnfQDwA/Q/PhYRfO72xfR7Hn4BIA3AfwcwMga+fE9AC8B2Idm8I13wI9b0fxIvw/AC61/d3b6mET86OgxAfDbaBbF3YfmG81/PueafRrAAQD/F0BpNfvRL/yESJTUF/yESBYFvxCJouAXIlEU/EIkioJfiERR8AuRKAp+IRJFwS9Eovx/I+RL+AXYaQ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(x_test[1].shape)\n",
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5转Eran格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T16:39:43.913907Z",
     "start_time": "2019-11-06T16:39:31.450814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5 conv2d_23\n",
      "1 5 conv2d_24\n",
      "2 5 permute_6\n",
      "3 5 flatten_7\n",
      "4 5 dense_11\n",
      "True (32, 7, 7)\n",
      "5 5 dense_12\n",
      "False (32, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 保证所有数据能够显示，而不是用省略号表示，np.inf表示一个足够大的数\n",
    "np.set_printoptions(threshold = np.inf) \n",
    "# 若想不以科学计数显示:\n",
    "np.set_printoptions(suppress = True)\n",
    "np.set_printoptions(linewidth = np.inf)\n",
    "\n",
    "    \n",
    "def get_name_map():\n",
    "    return {'conv2d':'Conv2D','max_pooling2d':'MaxPooling2D','sigmoid':'Sigmoid',\\\n",
    "            'relu':'ReLU','linear':'Affine','tanh':'Tanh','softmax':'Affine'}\n",
    "\n",
    "def extract_con2d(fs,layer):\n",
    "    weights = layer.get_weights()\n",
    "    filters = layer.filters\n",
    "    kernel_size = list(layer.kernel_size)\n",
    "    input_shape = list(layer.input_shape)\n",
    "    if len(input_shape)==4:\n",
    "        input_shape = input_shape[1:]\n",
    "    strides = list(layer.strides)\n",
    "    fs.write('Conv2D\\n')\n",
    "    name_map = get_name_map()\n",
    "    name = layer.activation.__name__.lower()\n",
    "    fs.write(name_map[name]+',')\n",
    "    fs.write('filters='+str(filters)+',')\n",
    "    fs.write('kernel_size='+str(kernel_size)+',')\n",
    "    fs.write('input_shape='+str(input_shape)+',')\n",
    "    fs.write('stride='+str(strides)+',')\n",
    "    #   tf中padding=='same'表示全填充,valid表示不填充，padding=0表示不填充,padding=1四周都填充\n",
    "    if layer.padding.lower()=='same':\n",
    "        fs.write('padding=1\\n')\n",
    "    else: \n",
    "        # valid\n",
    "        fs.write('padding=0\\n')\n",
    "    fs.write(str(weights[0].tolist())+'\\n')\n",
    "    fs.write(str(weights[1].tolist())+'\\n')\n",
    "\n",
    "def extract_max_pooling(fs,layer):\n",
    "    weights = layer.get_weights()\n",
    "    pool_size = list(layer.pool_size)\n",
    "    input_shape = list(layer.input_shape)\n",
    "    if len(input_shape)==4:\n",
    "        input_shape = input_shape[1:]\n",
    "    strides = list(layer.strides)\n",
    "    fs.write('MaxPooling2D\\n')\n",
    "    fs.write('pool_size='+str(pool_size)+',')\n",
    "    fs.write('input_shape='+str(input_shape)+'\\n')\n",
    "#     fs.write('stride='+str(strides)+'\\n')\n",
    "\n",
    "def extract_dense_activation(fs,layer):\n",
    "    weights = layer.get_weights()\n",
    "    name_map = get_name_map()\n",
    "    name = layer.activation.__name__.lower()\n",
    "    #if name in ['sigmoid','tanh','softmax']:\n",
    "    fs.write(name_map[name]+'\\n')\n",
    "    global has_permute\n",
    "    global permute_shape\n",
    "    print(has_permute,permute_shape)\n",
    "    if has_permute:\n",
    "        has_permute = False\n",
    "        wp = dict()\n",
    "        length = weights[0].shape[0]\n",
    "        warr = np.zeros(length)\n",
    "        new_w = np.zeros(weights[0].shape)\n",
    "        for i in range(length):\n",
    "            wp[weights[0][i,0]] = weights[0][i]\n",
    "            warr[i]=weights[0][i,0]\n",
    "        warr = warr.reshape(permute_shape)\n",
    "        warr = np.transpose(warr,(1,2,0))\n",
    "        warr = warr.flatten()\n",
    "        for i in range(length):\n",
    "            new_w[i]=wp[warr[i]]\n",
    "        fs.write(str(np.transpose(new_w).tolist())+'\\n')\n",
    "    else:\n",
    "        fs.write(str(np.transpose(weights[0]).tolist())+'\\n')\n",
    "    fs.write(str(weights[1].tolist())+'\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "model = load_model('neurify_convnet.h5')\n",
    "#print(model.layers[0].get_weights()[0].shape)\n",
    "has_permute = False\n",
    "permute_shape = ()\n",
    "# with open('test_cnn.tf', 'w') as fs:\n",
    "#    write4D(fs,model.layers[0].get_weights()[0])\n",
    "with open('neurify_convnet.tf', 'w') as fs:\n",
    "#     print(model.layers[0].input_shape,model.layers[0].output_shape,model.layers[0].kernel_size)\n",
    "#     print(model.layers[1].input_shape,model.layers[0].output_shape,model.layers[0].kernel_size)\n",
    "#     fs.write(str(model.layers[0].get_weights()[0].tolist())+'\\n')\n",
    "#     fs.write(str(model.layers[0].get_weights()[0]))\n",
    "    for index,layer in enumerate(model.layers):\n",
    "        print(index,len(model.layers)-1,layer.name.lower())\n",
    "        if 'conv2d' in layer.name.lower():\n",
    "            extract_con2d(fs,layer)\n",
    "        elif 'max_pooling' in layer.name.lower():\n",
    "            extract_max_pooling(fs,layer)\n",
    "        elif 'dense' in layer.name.lower() and index==len(model.layers)-1:\n",
    "            extract_dense_activation(fs,layer)\n",
    "        elif 'dense' in layer.name.lower():\n",
    "            extract_dense_activation(fs,layer)\n",
    "        elif 'flatten' in layer.name.lower():\n",
    "            continue\n",
    "        elif 'permute' in layer.name.lower():\n",
    "            has_permute = True\n",
    "            permute_shape = tuple(layer.output_shape[1:])\n",
    "            continue \n",
    "        elif 'dropout' in layer.name.lower():\n",
    "            continue\n",
    "        else:\n",
    "            print('not support layer',layer.name)\n",
    "\n",
    "    \n",
    "# for item in model.__dict__.items():\n",
    "#     print(item)\n",
    "# for index,layer in enumerate(model.layers):\n",
    "#     print(index,layer.name)\n",
    "# layer = model.layers[4]\n",
    "\n",
    "# print(layer.__name__)\n",
    "# weights = layer.get_weights()\n",
    "# print(layer.input_shape)\n",
    "# bias = weights[1].tolist()\n",
    "# print(len(bias))\n",
    "# s3 = ','.join([str(x) for x in weights[0][:,0].tolist()])+','\n",
    "# print(s3)\n",
    "# s = str(weights[0][:,0].tolist())\n",
    "# print(s)\n",
    "# s1 = s[1:len(s)-1]+','\n",
    "# s2 = s1.replace(' ','')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('neurify_convnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_spec', InputSpec(ndim=4))\n",
      "('supports_masking', False)\n",
      "('stateful', False)\n",
      "('_trainable_weights', [])\n",
      "('_non_trainable_weights', [])\n",
      "('_losses', [])\n",
      "('_updates', [])\n",
      "('_per_input_losses', {})\n",
      "('_per_input_updates', {})\n",
      "('_built', True)\n",
      "('_metrics', [])\n",
      "('_inbound_nodes', [<keras.engine.base_layer.Node object at 0x7f2e843926d0>])\n",
      "('_outbound_nodes', [<keras.engine.base_layer.Node object at 0x7f2e843a2990>])\n",
      "('name', 'permute_6')\n",
      "('trainable', True)\n",
      "('dtype', 'float32')\n",
      "('_initial_weights', None)\n",
      "('dims', (3, 1, 2))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for item in model.layers[2].__dict__.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eran转Mipverify与Jurify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T03:00:29.417542Z",
     "start_time": "2019-10-28T03:00:29.086225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1307 0.3081\n",
      "(4, 4, 1, 16) (16,)\n",
      "(4, 4, 16, 32) (32,)\n",
      "(800, 100) (100,)\n",
      "(100, 10) (10,)\n",
      "/model_weights/conv2d_7/conv2d_7\n",
      "['bias:0' 'kernel:0']\n",
      "/model_weights/conv2d_8/conv2d_8\n",
      "['bias:0' 'kernel:0']\n",
      "/model_weights/dense_7/dense_7\n",
      "['bias:0' 'kernel:0']\n",
      "/model_weights/dense_8/dense_8\n",
      "['bias:0' 'kernel:0']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json,re\n",
    "import scipy.io as sio\n",
    "class Eran2MipverifyAndJurify:\n",
    "    def transform2Mipverify(self,path):\n",
    "        basename = os.path.basename(path)\n",
    "        shotname, extension = os.path.splitext(basename)\n",
    "        mip = \"eran_\"+shotname\n",
    "        miptmp = dict()\n",
    "        f = open(path)\n",
    "        line = f.readline().strip()\n",
    "        index=1\n",
    "        while line != '':\n",
    "            if line.lower() == 'relu':\n",
    "                weights = np.array(eval(f.readline().strip()))\n",
    "                bias = np.array(eval(f.readline().strip()))\n",
    "                print(weights.shape,bias.shape)\n",
    "                # mipverify\n",
    "                miptmp['fc'+str(index)+'/weight']=np.transpose(weights)\n",
    "                miptmp['fc'+str(index)+'/bias']=np.transpose(bias)\n",
    "            line = f.readline().strip()\n",
    "            index+=1\n",
    "        sio.savemat(\"{}.mat\".format(mip), miptmp)\n",
    "        \n",
    "    def transform2Jurify(self,path):\n",
    "        basename = os.path.basename(path)\n",
    "        shotname, extension = os.path.splitext(basename)\n",
    "        ju = \"eran_\"+shotname+'.net'\n",
    "        jutmp=\"\"\n",
    "        f = open(path)\n",
    "        line = f.readline().strip()\n",
    "        while line != '':\n",
    "            if line.lower() == 'relu':\n",
    "                weights = np.array(eval(f.readline().strip()))\n",
    "                bias = np.array(eval(f.readline().strip()))\n",
    "                print(weights.shape,bias.shape)\n",
    "                # jurify\n",
    "                obj = {'layer_name': 'Dense', 'input_shape': [], 'units': 0, 'use_bias': True, 'activation': 'relu'}\n",
    "                obj['input_shape']=[weights.shape[1]]\n",
    "                obj['units']=weights.shape[0]\n",
    "                res=json.dumps(obj)\n",
    "                jutmp += res+'\\n'\n",
    "                for w in weights:\n",
    "                    jutmp += str(w.tolist())[1:-1]+',\\n'\n",
    "                for b in bias:\n",
    "                    jutmp += str(b)+',\\n'\n",
    "            line = f.readline().strip()\n",
    "        with open(ju, 'w') as fs:\n",
    "            fs.write(jutmp)\n",
    "            \n",
    "    def transform2H5(self,path,h5_file):\n",
    "        layers=[]\n",
    "        f = open(path)\n",
    "        line = f.readline().strip()\n",
    "        while line != '':\n",
    "            if 'Normalize' in line:\n",
    "                mean = self.extract_mean(line)[0]\n",
    "                std = self.extract_std(line)[0]\n",
    "                print(mean,std)\n",
    "            elif line == 'Conv2D':\n",
    "                line = f.readline().strip()\n",
    "#                 first_str = line.split(',')[0]\n",
    "#                 start = len(first_str)+1\n",
    "#                 args =  self.runRepl(line[start:-1], [\"filters\", \"input_shape\", \"kernel_size\", \"stride\", \"padding\"])\n",
    "                weight = np.array(eval(f.readline().strip()))\n",
    "                bias = np.array(eval(f.readline().strip()))\n",
    "#                 weight = np.transpose(weight)\n",
    "#                 weight = weight.transpose(1,0,2,3)\n",
    "                print(weight.shape,bias.shape)\n",
    "                layers.append((weight,bias))\n",
    "            elif line == \"ReLU\":\n",
    "                weight = np.array(eval(f.readline().strip()))\n",
    "                bias = np.array(eval(f.readline().strip()))\n",
    "                weight = np.transpose(weight)\n",
    "                print(weight.shape,bias.shape)\n",
    "                layers.append((weight,bias))\n",
    "            elif line == \"Affine\":\n",
    "                weight = np.array(eval(f.readline().strip()))\n",
    "                bias = np.array(eval(f.readline().strip()))\n",
    "                weight = np.transpose(weight)\n",
    "                print(weight.shape,bias.shape)\n",
    "                layers.append((weight,bias))\n",
    "            line = f.readline().strip()\n",
    "        self.to_h5(layers,h5_file)\n",
    "                \n",
    "    def runRepl(self,arg, repl):\n",
    "        for a in repl:\n",
    "            arg = arg.replace(a+\"=\", \"'\"+a+\"':\")\n",
    "        return eval(\"{\"+arg+\"}\")\n",
    "            \n",
    "    def extract_mean(self,text):\n",
    "        mean = ''\n",
    "        m = re.search('mean=\\[(.+?)\\]', text)\n",
    "        if m:\n",
    "            means = m.group(1)\n",
    "        mean_str = means.split(',')\n",
    "        num_means = len(mean_str)\n",
    "        mean_array = np.zeros(num_means)\n",
    "        for i in range(num_means):\n",
    "             mean_array[i] = np.float64(mean_str[i])\n",
    "        return mean_array\n",
    "\n",
    "    def extract_std(self,text):\n",
    "        std = ''\n",
    "        m = re.search('std=\\[(.+?)\\]', text)\n",
    "        if m:\n",
    "            stds = m.group(1)\n",
    "        std_str =stds.split(',')\n",
    "        num_std = len(std_str)\n",
    "        std_array = np.zeros(num_std)\n",
    "        for i in range(num_std):\n",
    "            std_array[i] = np.float64(std_str[i])\n",
    "        return std_array\n",
    "    \n",
    "    def to_h5(self,layers,h5_file):\n",
    "        f = h5py.File(h5_file, 'r+')\n",
    "        for group in f.keys():\n",
    "            group_read = f[group]\n",
    "            if group_read.name == \"/model_weights\":\n",
    "                for index,subgroup in enumerate(group_read.keys()):\n",
    "                    dset_read = f[group + '/' + subgroup]\n",
    "                    for dset in dset_read.keys():\n",
    "                        dset1 = f[group + '/' + subgroup + '/' + dset]\n",
    "                        print(dset1.name)\n",
    "                        wb = np.array(dset1)\n",
    "                        print(wb)\n",
    "                        kernel = dset1.name+ '/'+wb[1] #f[dset1.name+ '/'+wb[1]].name\n",
    "                        bias = dset1.name+ '/'+wb[0] #f[dset1.name+ '/'+wb[0]].name\n",
    "                        del f[kernel]\n",
    "                        del f[bias]\n",
    "                        f.create_dataset(kernel, data=layers[index][0])\n",
    "                        f.create_dataset(bias, data=layers[index][1])\n",
    "        f.close()\n",
    "\n",
    "nn = Eran2MipverifyAndJurify()\n",
    "# nn.transform2Mipverify('mnist_relu_6_100.tf')\n",
    "nn.transform2H5('convSmallRELU_Point.pyt','conv_3604_check.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=model.layers[4].get_weights()\n",
    "a[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eran转h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 16)        272       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 32)          8224      \n",
      "_________________________________________________________________\n",
      "permute_3 (Permute)          (None, 32, 5, 5)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               80100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,606\n",
      "Trainable params: 89,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28,1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (4, 4), strides=(2, 2), padding=\"valid\", activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (4, 4), strides=(2, 2), padding=\"valid\", activation='relu'))\n",
    "model.add(Permute((3,1,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100,activation='relu'))\n",
    "model.add(Dense(units=10,activation='linear'))\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.save(\"conv_3604_check.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jurify转Neurify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:35:14.589611Z",
     "start_time": "2019-11-05T00:35:14.386501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Mylayer object at 0x14922d128>, <__main__.Mylayer object at 0x14922d2e8>, <__main__.Mylayer object at 0x14922d390>, <__main__.Mylayer object at 0x14922d438>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json,os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "class Mylayer:\n",
    "    layer_name = ''\n",
    "    input_shape= []\n",
    "    units = 0\n",
    "    use_bias = True\n",
    "    activation = 'relu'\n",
    "    weights = []\n",
    "    bias = []\n",
    "\n",
    "class Jurify2Neurify:\n",
    "    file = \"\"\n",
    "    file_str = \"\"\n",
    "    layer_number = 0\n",
    "    input_size = 0\n",
    "    output_size = 0\n",
    "    max_layer_size = 0\n",
    "    layer_sizes = []\n",
    "    layer_types = []\n",
    "    layer_map = {'Dense':'0','Conv2D':'1','MaxPooling2D':'2','Flatten':'3'}\n",
    "    def extract_dense(self,layer):        \n",
    "        ws = layer.weights\n",
    "        self.layer_sizes.append(layer.units)\n",
    "        temp = ''\n",
    "        for i in range(layer.units):\n",
    "            temp += ','.join([str(x) for x in ws[i,:].tolist()])+',\\n'\n",
    "        self.file_str += temp\n",
    "        use_bias = layer.use_bias\n",
    "        if use_bias:\n",
    "            bias = layer.bias.tolist()\n",
    "            self.file_str += ',\\n'.join([str(x) for x in bias])+',\\n'\n",
    "        self.extract_layer_type(layer.layer_name)\n",
    "    \n",
    "    def extract_layer_type(self,layer_name):\n",
    "        if layer_name in ['Dense','Conv2D']:\n",
    "            self.layer_types.append(self.layer_map[layer_name])\n",
    "        else:\n",
    "            # 不支持 其他层\n",
    "            print('not support layer:',layer_name)\n",
    "            raise RuntimeError('not support layer: '+layer_name)\n",
    "    \n",
    "    def transform2Neurify(self,path):\n",
    "        model = self.load_model(path)\n",
    "        print(model)\n",
    "        basename = os.path.basename(path)\n",
    "        shotname, extension = os.path.splitext(path)\n",
    "        file = shotname+'.nnet'\n",
    "        self.layer_number = len(model)\n",
    "        for index,layer in enumerate(model):\n",
    "            if index == 0:\n",
    "                if layer.layer_name == 'Dense':\n",
    "                    self.input_size=layer.input_shape[0]\n",
    "                    self.layer_sizes.append(layer.input_shape[0])\n",
    "                else:\n",
    "                    self.input_size=layer.input_shape\n",
    "                    self.layer_sizes.append(layer.input_shape)\n",
    "            if layer.layer_name=='Dense':\n",
    "                self.extract_dense(layer)\n",
    "        self.output_size = self.layer_sizes[-1]\n",
    "        self.max_layer_size = max(self.layer_sizes)\n",
    "        with open(file, 'w') as fs:\n",
    "            linestr1 = [self.layer_number,self.input_size,self.output_size,self.max_layer_size]\n",
    "            linestr1 = ','.join([str(x) for x in linestr1])+',\\n'\n",
    "            linestr2 = ','.join([str(x) for x in self.layer_sizes])+',\\n'\n",
    "            linestr3 = ','.join([str(x) for x in self.layer_types])+',\\n'\n",
    "            fs.write(linestr1)\n",
    "            fs.write(linestr2)\n",
    "            fs.write(linestr3)\n",
    "            fs.write(self.file_str)\n",
    "            \n",
    "    def load_model(self,path):\n",
    "        model = []\n",
    "        f = open(path)\n",
    "        line = f.readline().strip()\n",
    "        while '//' in line:\n",
    "            line = f.readline().strip()\n",
    "        while line != '':\n",
    "            obj = json.loads(line)\n",
    "            ml = Mylayer()\n",
    "            if obj['layer_name'] == 'Dense':\n",
    "                ml.layer_name = obj['layer_name']\n",
    "                ml.input_shape = obj['input_shape']\n",
    "                ml.units = obj['units']\n",
    "                ml.use_bias = obj['use_bias']\n",
    "                ml.activation = obj['activation']\n",
    "                wtmp = ''\n",
    "                for _ in range(ml.units):\n",
    "                    wtmp += '['+f.readline().strip()[:-1]+'],'\n",
    "                wtmp = '['+wtmp[:-1]+']'\n",
    "                ml.weights = np.array(eval(wtmp))\n",
    "                if ml.use_bias:\n",
    "                    btmp = ''\n",
    "                    for _ in range(ml.units):\n",
    "                        btmp += f.readline().strip()\n",
    "                    btmp = '['+btmp[:-1]+']'\n",
    "                    ml.bias = np.array(eval(btmp)) \n",
    "            model.append(ml)  \n",
    "            line = f.readline().strip()\n",
    "        return model\n",
    "    \n",
    "nn = Jurify2Neurify()\n",
    "nn.transform2Neurify('model/mnist/jurify_model/mnist_model_3_50_adam.v')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurify转h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:35:06.053973Z",
     "start_time": "2020-08-04T05:35:05.557486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 16)        272       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 32)          8224      \n",
      "_________________________________________________________________\n",
      "permute_4 (Permute)          (None, 32, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               156900    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 166,406\n",
      "Trainable params: 166,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28,1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (4, 4), strides=(2, 2), padding=\"same\", activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (4, 4), strides=(2, 2), padding=\"same\", activation='relu'))\n",
    "model.add(Permute((3,1,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100,activation='relu'))\n",
    "model.add(Dense(units=10,activation='linear'))\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.save(\"neurify_convnet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T13:00:51.476675Z",
     "start_time": "2020-07-29T13:00:51.463678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/model_weights/conv2d_23/conv2d_23\n",
      "['bias:0' 'kernel:0']\n",
      "(4, 4, 1, 16) (16,)\n",
      "/model_weights/conv2d_24/conv2d_24\n",
      "['bias:0' 'kernel:0']\n",
      "(4, 4, 16, 32) (32,)\n",
      "/model_weights/dense_11/dense_11\n",
      "['bias:0' 'kernel:0']\n",
      "(1568, 100) (100,)\n",
      "/model_weights/dense_12/dense_12\n",
      "['bias:0' 'kernel:0']\n",
      "(100, 10) (10,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f = h5py.File('check_convnet.h5', 'r+')\n",
    "\n",
    "for group in f.keys(): #可以查看所有的主键\n",
    "#     print(f[group].name)\n",
    "    group_read = f[group]\n",
    "    # 遍历该一级组下面的子组\n",
    "    if f[group].name == \"/model_weights\":\n",
    "        for subgroup in group_read.keys():\n",
    "    #         print(subgroup)\n",
    "            # 根据一级组和二级组名获取其下面的dataset\n",
    "            dset_read = f[group + '/' + subgroup]\n",
    "            # 遍历该子组下所有的dataset\n",
    "            for dset in dset_read.keys():\n",
    "                # 获取dataset数据\n",
    "                dset1 = f[group + '/' + subgroup + '/' + dset]\n",
    "    #             print('****   ',(group + '/' + subgroup + '/' + dset))\n",
    "                print(dset1.name)\n",
    "                wb = np.array(dset1)\n",
    "                print(wb)\n",
    "                kernel = f[dset1.name+ '/'+wb[1]]\n",
    "                bias = f[dset1.name+ '/'+wb[0]]\n",
    "                print(np.array(kernel).shape,np.array(bias).shape)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:35:25.868716Z",
     "start_time": "2020-08-04T05:35:25.796890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 1, 16) (16,)\n",
      "(4, 4, 16, 32) (32,)\n",
      "(1568, 100) (100,)\n",
      "(100, 10) (10,)\n",
      "/model_weights/conv2d_7/conv2d_7\n",
      "['bias:0' 'kernel:0']\n",
      "/model_weights/conv2d_8/conv2d_8\n",
      "['bias:0' 'kernel:0']\n",
      "/model_weights/dense_7/dense_7\n",
      "['bias:0' 'kernel:0']\n",
      "/model_weights/dense_8/dense_8\n",
      "['bias:0' 'kernel:0']\n"
     ]
    }
   ],
   "source": [
    "def neurify_h5(layers,h5_file):\n",
    "    f = h5py.File(h5_file, 'r+')\n",
    "    for group in f.keys():\n",
    "        group_read = f[group]\n",
    "        if group_read.name == \"/model_weights\":\n",
    "            for index,subgroup in enumerate(group_read.keys()):\n",
    "                dset_read = f[group + '/' + subgroup]\n",
    "                for dset in dset_read.keys():\n",
    "                    dset1 = f[group + '/' + subgroup + '/' + dset]\n",
    "                    print(dset1.name)\n",
    "                    wb = np.array(dset1)\n",
    "                    print(wb)\n",
    "                    kernel = dset1.name+ '/'+wb[1] #f[dset1.name+ '/'+wb[1]].name\n",
    "                    bias = dset1.name+ '/'+wb[0] #f[dset1.name+ '/'+wb[0]].name\n",
    "                    del f[kernel]\n",
    "                    del f[bias]\n",
    "                    f.create_dataset(kernel, data=layers[index][0])\n",
    "                    f.create_dataset(bias, data=layers[index][1])\n",
    "    f.close()\n",
    "    \n",
    "def neurify2h5(nnet_path,h5_file):\n",
    "    f = open(nnet_path)\n",
    "    line = f.readline().strip()\n",
    "    while '//' in line:\n",
    "        line = f.readline().strip()\n",
    "    layer_sizes = list(map(int,f.readline().strip().split(',')[:-1]))\n",
    "    line = f.readline().strip().split(',')[:-1]\n",
    "    conv = []\n",
    "    layers=[]\n",
    "    for layer_type in line:\n",
    "        if layer_type == '1':\n",
    "            conv.append(tuple(list(map(int,f.readline().strip().split(',')[:-1]))))\n",
    "    for index,layer_type in enumerate(line):\n",
    "        if layer_type == '1':\n",
    "            out_channel, in_channel, kernel, stride, padding = conv[index]\n",
    "            weights=np.zeros((out_channel, in_channel*kernel*kernel))\n",
    "            bias = []\n",
    "            for i in range(out_channel):\n",
    "                tmp = f.readline().strip().split(',')[:-1]\n",
    "                tmp = np.array(list(map(float,tmp)))\n",
    "                weights[i] = tmp\n",
    "    #             if i==0:\n",
    "    #                 print(weights[i].tolist())\n",
    "            for _ in range(out_channel):\n",
    "                bias.append(float(f.readline().strip().split(',')[0]))\n",
    "            bias = np.array(bias)\n",
    "            weights = weights.reshape((out_channel, in_channel,kernel,kernel))\n",
    "            weights = weights.transpose(2,3,1,0)\n",
    "    #         print(weights[:,:,0,0].flatten().tolist())\n",
    "            print(weights.shape,bias.shape)\n",
    "            layers.append((weights,bias))\n",
    "        elif layer_type == '0':\n",
    "            layer_size1 = layer_sizes[index]\n",
    "            layer_size2 = layer_sizes[index+1]\n",
    "            weights = np.zeros((layer_size1, layer_size2))\n",
    "            for i in range(layer_size2):\n",
    "                tmp = f.readline().strip().split(',')[:-1]\n",
    "                weights[:,i] = np.array(list(map(float,tmp)))\n",
    "            bias = []\n",
    "            for _ in range(layer_size2):\n",
    "                bias.append(float(f.readline().strip().split(',')[0]))\n",
    "            bias = np.array(bias)\n",
    "            print(weights.shape,bias.shape)\n",
    "            layers.append((weights,bias))\n",
    "    neurify_h5(layers,h5_file)\n",
    "\n",
    "# neurify2h5('../conv.nnet','neurify_convnet.h5')\n",
    "neurify2h5('../conv_kolter.nnet','neurify_convnet_kolter.h5')\n",
    "# neurify2h5('../conv_madry.nnet','neurify_convnet_madry.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 校验转换后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:17:20.859914Z",
     "start_time": "2020-08-04T05:17:19.817148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "100/100 [==============================] - 0s 692us/step\n",
      "LOSS: 17.513025054931642 ACCU: 0.07999999821186066\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    print(x_train.shape)\n",
    "     # 归一化\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    x_train = x_train.reshape(60000,28,28,1)\n",
    "    x_test = x_test.reshape(10000,28,28,1)\n",
    "    # 标签激活\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "x_train, y_train, x_test, y_test = preprocessing_data()\n",
    "# x_test = (x_test - 0.1307) / 0.3081\n",
    "m = load_model(\"neurify_convnet.h5\")\n",
    "score = m.evaluate(x_test[0:100],y_test[0:100])\n",
    "print(\"LOSS:\",score[0],\"ACCU:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T05:35:45.480639Z",
     "start_time": "2020-08-04T05:35:44.921430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5124834  -1.1882081  -3.3500195  -1.8102367   1.6668084   1.7427851\n",
      " -2.7868142   0.11994095 -0.4377843   0.61423266]\n"
     ]
    }
   ],
   "source": [
    "m = load_model(\"neurify_convnet_kolter.h5\")\n",
    "intermediate_model = Model(inputs = m.input,outputs = m.layers[-1].output)\n",
    "out = intermediate_model.predict(x_test[0:1])\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5转Neurify格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T15:34:43.237695Z",
     "start_time": "2020-07-29T15:34:40.527662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转化完成!\n"
     ]
    }
   ],
   "source": [
    "# only weights\n",
    "\n",
    "# in_placeholder = Input(shape=(784,))\n",
    "# x = Dense(50, activation='relu')(in_placeholder)\n",
    "# x = Dense(50, activation='relu')(x)\n",
    "# x = Dense(10, name='before_softmax')(x)\n",
    "# x = Activation('softmax', name='predictions')(x)\n",
    "# model = Model(in_placeholder, x)\n",
    "# model.load_weights('./FCModel_new50.h5')\n",
    "\n",
    "class Convert2NeurifyNet:\n",
    "    exist_input = False\n",
    "    exist_conv = False\n",
    "    layer_number = 0\n",
    "    input_size = 0\n",
    "    output_size = 0\n",
    "    max_layer_size = 0\n",
    "    layer_sizes = []\n",
    "    layer_types = []\n",
    "    layer_map = {'Dense':'0','Conv2D':'1','MaxPooling2D':'2','Flatten':'3'}\n",
    "    activation_types = []\n",
    "    # 恒等:0  relu:1  Tanh:2  Sigmod:3  Softmax:4\n",
    "    act_map = {'linear':'0','sigmoid':'3','relu':'1','tanh':'2','softmax':'4'}\n",
    "    all_weights_bias = ''\n",
    "    # 每个卷积层的参数集合\n",
    "    conv_params_list = []\n",
    "    \n",
    "    def extract_con2d(self,layer,next_layer_is_activation,is_maxpool_or_flatten):\n",
    "        self.exist_conv = True\n",
    "        self.layer_number += 1\n",
    "        weights = layer.get_weights()\n",
    "        kernel_size = list(layer.kernel_size)\n",
    "        input_shape = list(layer.input_shape)\n",
    "        if len(input_shape)==4:\n",
    "            input_shape = input_shape[1:]\n",
    "        output_shape = list(layer.output_shape)\n",
    "        if len(output_shape)==4:\n",
    "            output_shape = output_shape[1:]\n",
    "        # 如果图模型中没有显示的input层而是隐示的,第一层中获取inputshape\n",
    "        if not self.exist_input:\n",
    "            self.input_size = input_shape[0]*input_shape[1]*input_shape[2]\n",
    "            self.layer_sizes.append(self.input_size)\n",
    "            self.exist_input = True\n",
    "        # 加入本层的神经元数量\n",
    "        self.layer_sizes.append(output_shape[0]*output_shape[1]*output_shape[2])\n",
    "        filters = layer.filters\n",
    "        strides = list(layer.strides)\n",
    "        padding = '1' if layer.padding.lower()=='same' else '0'\n",
    "        weights = layer.get_weights()\n",
    "        ws = weights[0]\n",
    "        _,_,inchannel,outchannel = ws.shape\n",
    "        # 加入卷积参数\n",
    "        self.conv_params_list.append([str(outchannel),str(inchannel),str(kernel_size[0]),str(strides[0]),padding])\n",
    "        temp = ''\n",
    "        # 纬度转换,变成(outchannel,inchannel,h,w) 方便拉平导出\n",
    "        w_t = ws.transpose(3,2,0,1)\n",
    "        for i in range(outchannel):\n",
    "            temp += ','.join([str(x) for x in w_t[i,:,:,:].flatten().tolist()])+',\\n'\n",
    "#             temp += ','.join([str(x) for x in w_t[:,:,:,i].flatten().tolist()])+',\\n'\n",
    "        self.all_weights_bias += temp\n",
    "        use_bias = layer.use_bias\n",
    "        if use_bias:\n",
    "            bias = weights[1].tolist()\n",
    "            self.all_weights_bias += ',\\n'.join([str(x) for x in bias])+',\\n'\n",
    "        # 判断下一层不是激活函数层或者是最大池化层与降维层\n",
    "        if not next_layer_is_activation or is_maxpool_or_flatten:\n",
    "            activation_name = layer.activation.__name__\n",
    "            self.extract_activation_type(activation_name)\n",
    "        # 抽取层类型\n",
    "        self.extract_layer_type(type(layer).__name__)\n",
    "        \n",
    "    def extract_flatten(self,layer):   \n",
    "        self.output_size = units\n",
    "        \n",
    "    def extract_max_pooling(self,layer,is_maxpool_or_flatten):\n",
    "        weights = layer.get_weights()\n",
    "        pool_size = list(layer.pool_size)\n",
    "        input_shape = list(layer.input_shape)\n",
    "        if len(input_shape)==4:\n",
    "            input_shape = input_shape[1:]\n",
    "        strides = list(layer.strides)\n",
    "\n",
    "    def extract_dense(self,layer,next_layer_is_activation,the_last_but_one,is_last_one):\n",
    "        self.layer_number += 1\n",
    "        input_shape = list(layer.input_shape)\n",
    "        if len(input_shape)==4:\n",
    "            input_shape = input_shape[1:]\n",
    "        # 如果图模型中没有显示的input层而是隐示的,第一层中获取inputshape\n",
    "        if not self.exist_input:\n",
    "            if len(input_shape)==2:\n",
    "                self.input_size = input_shape[1]\n",
    "            else:\n",
    "                self.input_size = input_shape[0]*input_shape[1]*input_shape[2]\n",
    "            self.layer_sizes.append(self.input_size)\n",
    "            self.exist_input = True\n",
    "        # 抽取与转化权重和偏置\n",
    "        weights = layer.get_weights()\n",
    "        ws = weights[0]\n",
    "        units = layer.units\n",
    "        self.layer_sizes.append(units)\n",
    "        temp = ''\n",
    "        for i in range(units):\n",
    "            temp += ','.join([str(x) for x in ws[:,i].tolist()])+',\\n'\n",
    "        self.all_weights_bias += temp\n",
    "        use_bias = layer.use_bias\n",
    "        if use_bias:\n",
    "            bias = weights[1].tolist()\n",
    "            self.all_weights_bias += ',\\n'.join([str(x) for x in bias])+',\\n'\n",
    "        # 判断下一层不是激活函数层，那么需要加入Dense的激活函数\n",
    "        if not next_layer_is_activation:\n",
    "            activation_name = layer.activation.__name__\n",
    "            self.extract_activation_type(activation_name)\n",
    "        # 如果本层是倒数第二层，并且最后一层是激活函数\n",
    "        if (next_layer_is_activation and the_last_but_one) or is_last_one:\n",
    "            self.output_size = units\n",
    "        # 抽取层类型\n",
    "        self.extract_layer_type(type(layer).__name__)\n",
    "        \n",
    "    def extract_input(self,layer):\n",
    "        # 输入层大小\n",
    "        self.layer_sizes.append(layer.input_shape[1])\n",
    "        self.input_size = layer.input_shape[1]\n",
    "        self.exist_input = True\n",
    "        \n",
    "    def extract_layer_type(self,layer_name):\n",
    "        if layer_name in ['Dense','Conv2D']:\n",
    "            self.layer_types.append(self.layer_map[layer_name])\n",
    "        else:\n",
    "            # 不支持 其他层\n",
    "            print('not support layer:',layer_name)\n",
    "            raise RuntimeError('not support layer: '+layer_name)\n",
    "    \n",
    "    def extract_activation_type(self,activation_name):\n",
    "        if activation_name in ['sigmod','tanh','linear','relu']:\n",
    "            self.activation_types.append(self.act_map[activation_name])\n",
    "        else:\n",
    "            if 'softmax' in activation_name:\n",
    "                # neurify由于获取的是未经过softmax激活函数前的数据，所以当做恒等函数来做\n",
    "                self.activation_types.append(self.act_map['linear'])\n",
    "            else:\n",
    "                # 不支持 'softmax'等其他激活函数\n",
    "                print('not support activation:',activation_name)\n",
    "                raise RuntimeError('not support activation: '+activation_name)\n",
    "    \n",
    "    def extract_model(self,model,path,fastVerify=False):\n",
    "        try:\n",
    "            \n",
    "            for index,layer in enumerate(model.layers):\n",
    "                layer_name = type(layer).__name__\n",
    "                # 判断是否采用的是Dense+Activation的分离写法，分离写法Dense层的激活层默认Linear\n",
    "                # 这个时候激活层类型不应该加入linear，而是加入下一层的激活层类型\n",
    "                # 总的层数也需要移除输入层和激活层的数量\n",
    "                next_layer_is_activation = False\n",
    "                is_maxpool_or_flatten = False\n",
    "                is_last_one = False\n",
    "                if index!=len(model.layers)-1:\n",
    "                    next_layer_name = type(model.layers[index+1]).__name__\n",
    "                    if 'Activation' in next_layer_name:\n",
    "                        next_layer_is_activation = True\n",
    "                    if 'MaxPooling2D' in next_layer_name or 'Flatten' in next_layer_name:\n",
    "                        is_maxpool_or_flatten = True\n",
    "                else:\n",
    "                    is_last_one = True\n",
    "#                 print(index,len(model.layers)-1,layer_name)\n",
    "                \n",
    "                if 'InputLayer' in layer_name:\n",
    "                    self.extract_input(layer)\n",
    "                elif 'Conv2D' in layer_name:\n",
    "                    self.extract_con2d(layer,next_layer_is_activation,is_maxpool_or_flatten)\n",
    "#                 elif 'MaxPooling2D' in layer_name:\n",
    "#                     self.extract_max_pooling(layer)\n",
    "                elif 'Activation' in layer_name:\n",
    "                    self.extract_activation_type(layer.activation.__name__)\n",
    "                elif 'Dense' in layer_name:\n",
    "                    # 是否是倒数第二层\n",
    "                    the_last_but_one = index==len(model.layers)-2\n",
    "                    self.extract_dense(layer,next_layer_is_activation,the_last_but_one,is_last_one)\n",
    "                elif 'Flatten' in layer_name:\n",
    "                    continue\n",
    "                elif 'Permute' in layer_name:\n",
    "                    continue \n",
    "                elif 'Dropout' in layer_name:\n",
    "                    continue\n",
    "                else:\n",
    "                    print('not support other layer:',layer_name)\n",
    "                        \n",
    "            self.max_layer_size = max(self.layer_sizes)\n",
    "            linestr1 = [self.layer_number,self.input_size,self.output_size,self.max_layer_size]\n",
    "            linestr1 = ','.join([str(x) for x in linestr1])+',\\n'\n",
    "            linestr2 = ','.join([str(x) for x in self.layer_sizes])+',\\n'\n",
    "            linestr3 = ','.join([str(x) for x in self.layer_types])+',\\n'\n",
    "            linestr4 = ','.join([str(x) for x in self.activation_types])+',\\n'\n",
    "            linestr5 = self.all_weights_bias\n",
    "            with open(path, 'w') as fs:\n",
    "                fs.write(linestr1)\n",
    "                fs.write(linestr2)\n",
    "                fs.write(linestr3)\n",
    "                # 修改版本fastverify需要各个激活层的类型\n",
    "                if fastVerify:  \n",
    "                    fs.write(linestr4)\n",
    "                # 如果存在卷积层,需要加入每个卷积层的参数(out_channel,in_channel,kernel_size,stride,padding)    \n",
    "                if self.exist_conv:\n",
    "                    for conv in self.conv_params_list:\n",
    "                        fs.write(','.join(conv)+',\\n')\n",
    "                fs.write(linestr5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Error occurred：',e)\n",
    "    \n",
    "model = load_model('conv_3604.h5')\n",
    "neurify_net = Convert2NeurifyNet()\n",
    "neurify_net.extract_model(model,'conv_3604.nnet',False)\n",
    "print('转化完成!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15770894 -0.3110294  -0.18281285 -0.09141599]\n",
      " [-0.06498437  0.10176975  0.13436964  0.1255412 ]\n",
      " [ 0.15979807  0.04313296  0.29523265  0.28294197]\n",
      " [ 0.15414602  0.1359642   0.23065095  0.06263968]]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./pure_cnn_model_mnist_0-1.h5')\n",
    "# model = load_model('./cnn_model_cifar10_5.h5')\n",
    "layer = model.layers[0]\n",
    "\n",
    "# print(type(layer).__name__)\n",
    "\n",
    "# for item in layer.__dict__.items():\n",
    "#     print(item)\n",
    "# print(layer.output_shape)\n",
    "weights = layer.get_weights()[0]\n",
    "# weights = weights.transpose(3,2,1,0)\n",
    "ws = weights[:,:,0,0]\n",
    "print(ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 1]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation = [0]\n",
    "permutation.extend([i for i in\n",
    "                    range(2, 4)])\n",
    "permutation.append(1)\n",
    "permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5转Jurify格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T09:25:32.215325Z",
     "start_time": "2020-01-03T09:25:28.392471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_name': 'Conv2D', 'input_shape': [32, 32, 3], 'output_shape': [32, 32, 16], 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 1, 'use_bias': True, 'activation': 'relu', 'filter_height': 3, 'filter_width': 3, 'in_channels': 3, 'out_channels': 16}\n",
      "{'layer_name': 'Conv2D', 'input_shape': [32, 32, 16], 'output_shape': [32, 32, 16], 'filters': 16, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 1, 'use_bias': True, 'activation': 'relu', 'filter_height': 3, 'filter_width': 3, 'in_channels': 16, 'out_channels': 16}\n",
      "{'layer_name': 'MaxPooling2D', 'pool_size': [2, 2], 'strides': [2, 2], 'padding': 0, 'input_shape': [32, 32, 16], 'output_shape': [16, 16, 16], 'activation': 'linear'}\n",
      "{'layer_name': 'Conv2D', 'input_shape': [16, 16, 16], 'output_shape': [16, 16, 32], 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 1, 'use_bias': True, 'activation': 'relu', 'filter_height': 3, 'filter_width': 3, 'in_channels': 16, 'out_channels': 32}\n",
      "{'layer_name': 'Conv2D', 'input_shape': [16, 16, 32], 'output_shape': [16, 16, 32], 'filters': 32, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 1, 'use_bias': True, 'activation': 'relu', 'filter_height': 3, 'filter_width': 3, 'in_channels': 32, 'out_channels': 32}\n",
      "{'layer_name': 'MaxPooling2D', 'pool_size': [2, 2], 'strides': [2, 2], 'padding': 0, 'input_shape': [16, 16, 32], 'output_shape': [8, 8, 32], 'activation': 'linear'}\n",
      "{'layer_name': 'Flatten', 'input_shape': [8, 8, 32], 'output_shape': [2048], 'activation': 'linear'}\n",
      "{'layer_name': 'Dense', 'input_shape': [2048], 'units': 100, 'use_bias': True, 'activation': 'relu'}\n",
      "{'layer_name': 'Dense', 'input_shape': [100], 'units': 10, 'use_bias': True, 'activation': 'softmax'}\n",
      "export successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 自己模型文件的格式\n",
    "\n",
    "# 保证所有数据能够显示，而不是用省略号表示，np.inf表示一个足够大的数\n",
    "np.set_printoptions(threshold = np.inf) \n",
    "# 若想不以科学计数显示:\n",
    "np.set_printoptions(suppress = True)\n",
    "np.set_printoptions(linewidth = np.inf)\n",
    "\n",
    "import json\n",
    "class Convert2MyTools:\n",
    "    def extract_con2d(self,fs,layer):\n",
    "        filters = layer.filters\n",
    "        kernel_size = list(layer.kernel_size)\n",
    "        input_shape = list(layer.input_shape)\n",
    "        output_shape = list(layer.output_shape)\n",
    "        if len(input_shape)==4 or input_shape[0]==None:\n",
    "            input_shape = input_shape[1:]\n",
    "        if len(output_shape)==4 or input_shape[0]==None:\n",
    "            output_shape = output_shape[1:]\n",
    "        strides = list(layer.strides)\n",
    "        #   tf中padding=='same'表示全填充,valid表示不填充，padding=0表示不填充,padding=1四周都填充\n",
    "        padding = 1 if layer.padding.lower()=='same' else 0\n",
    "        use_bias = layer.use_bias\n",
    "        obj = dict()\n",
    "        obj['layer_name'] = type(layer).__name__\n",
    "        obj['input_shape'] = list(map(int,input_shape))\n",
    "        obj['output_shape'] = list(map(int,output_shape))\n",
    "        obj['filters'] = filters\n",
    "        obj['kernel_size'] = kernel_size\n",
    "        obj['strides'] = strides\n",
    "        obj['padding'] = padding\n",
    "        obj['use_bias'] = use_bias\n",
    "        obj['activation'] = layer.activation.__name__\n",
    "        weights = layer.get_weights()\n",
    "        ws = weights[0]\n",
    "        (filter_height, filter_width, in_channels, out_channels) = ws.shape\n",
    "        obj['filter_height'] = filter_height\n",
    "        obj['filter_width'] = filter_width\n",
    "        obj['in_channels'] = in_channels\n",
    "        obj['out_channels'] = out_channels\n",
    "        print(obj)\n",
    "        res=json.dumps(obj)\n",
    "        fs.write(res+'\\n')\n",
    "        temp = ''\n",
    "        # tf中的纬度是h,w,inchannel,outchannel，纬度转换,变成(outchannel,inchannel,h,w) 方便拉平导出\n",
    "    #     w_t = ws.transpose(3,2,0,1)\n",
    "        # 上面拉平与neurify一致,但是存在问题,在实际卷积核中需要宽高维度转换\n",
    "        w_t = ws.transpose(3,2,1,0)\n",
    "        for i in range(out_channels):\n",
    "            temp += ','.join([str(x) for x in w_t[i,:,:,:].flatten().tolist()])+',\\n'\n",
    "        fs.write(temp)\n",
    "        temp = ''\n",
    "        if use_bias:\n",
    "            bias = weights[1].tolist()\n",
    "            temp = ',\\n'.join([str(x) for x in bias])+',\\n'\n",
    "        fs.write(temp)\n",
    "    #     fs.write(str(weights[0].tolist())+'\\n')\n",
    "    #     fs.write(str(weights[1].tolist())+'\\n')\n",
    "\n",
    "    def extract_max_pooling(self,fs,layer):\n",
    "        input_shape = list(layer.input_shape)\n",
    "        output_shape = list(layer.output_shape)\n",
    "        if len(input_shape)==4 or input_shape[0]==None:\n",
    "            input_shape = input_shape[1:]\n",
    "        if len(output_shape)==4 or output_shape[0]==None:\n",
    "            output_shape = output_shape[1:]\n",
    "        obj = dict()\n",
    "        obj['layer_name'] = type(layer).__name__\n",
    "        obj['pool_size'] = list(layer.pool_size)\n",
    "        obj['strides'] = list(layer.strides)\n",
    "        obj['padding'] = 1 if layer.padding.lower()=='same' else 0\n",
    "        obj['input_shape'] = list(map(int,input_shape))\n",
    "        obj['output_shape'] = list(map(int,output_shape))\n",
    "        obj['activation'] = 'linear'\n",
    "        print(obj)\n",
    "        res=json.dumps(obj)\n",
    "        fs.write(res+'\\n')\n",
    "\n",
    "    def extract_flatten(self,fs,layer):\n",
    "        input_shape = list(layer.input_shape)\n",
    "        output_shape = list(layer.output_shape)\n",
    "        if len(input_shape)==4 or input_shape[0]==None:\n",
    "            input_shape = input_shape[1:]\n",
    "        if len(output_shape)==4 or output_shape[0]==None:\n",
    "            output_shape = output_shape[1:]\n",
    "        obj = dict()\n",
    "        obj['layer_name'] = type(layer).__name__\n",
    "        obj['input_shape'] = list(map(int,input_shape))\n",
    "        obj['output_shape'] = list(map(int,output_shape))\n",
    "        obj['activation'] = 'linear'\n",
    "        print(obj)\n",
    "        res=json.dumps(obj)\n",
    "        fs.write(res+'\\n')\n",
    "\n",
    "    def extract_dense(self,fs,layer):\n",
    "        input_shape = list(layer.input_shape)\n",
    "    #     output_shape = list(layer.output_shape)\n",
    "        if len(input_shape)==4 or input_shape[0]==None:\n",
    "            input_shape = input_shape[1:]\n",
    "    #     if len(output_shape)==4 or input_shape[0]==None:\n",
    "    #         output_shape = output_shape[1:]\n",
    "        # 抽取与转化权重和偏置\n",
    "        weights = layer.get_weights()\n",
    "        ws = weights[0]\n",
    "        units = layer.units\n",
    "        use_bias = layer.use_bias\n",
    "        obj = dict()\n",
    "        obj['layer_name'] = type(layer).__name__\n",
    "        obj['input_shape'] = list(map(int,input_shape))\n",
    "    #     obj['output_shape'] = list(map(int,output_shape))\n",
    "        obj['units'] = units\n",
    "        obj['use_bias'] = use_bias\n",
    "        obj['activation'] = layer.activation.__name__\n",
    "        print(obj)\n",
    "        res=json.dumps(obj)\n",
    "        fs.write(res+'\\n')\n",
    "        temp = ''\n",
    "        for i in range(units):\n",
    "            temp += ','.join([str(x) for x in ws[:,i].tolist()])+',\\n'\n",
    "        fs.write(temp)\n",
    "        temp = ''\n",
    "        if use_bias:\n",
    "            bias = weights[1].tolist()\n",
    "            temp= ',\\n'.join([str(x) for x in bias])+',\\n'\n",
    "        fs.write(temp)\n",
    "\n",
    "    \n",
    "    def extract_model(self,model,path):\n",
    "        with open(path, 'w') as fs:\n",
    "            for index,layer in enumerate(model.layers):\n",
    "                layer_name = type(layer).__name__\n",
    "                if 'Conv2D' in layer_name:\n",
    "                    self.extract_con2d(fs,layer)\n",
    "                elif 'MaxPooling2D' in layer_name:\n",
    "                    self.extract_max_pooling(fs,layer)\n",
    "                elif 'Dense' in layer_name and index==len(model.layers)-1:\n",
    "                    self.extract_dense(fs,layer)\n",
    "                elif 'Dense' in layer_name:\n",
    "                    self.extract_dense(fs,layer)\n",
    "                elif 'Flatten' in layer_name:\n",
    "                    self.extract_flatten(fs,layer)\n",
    "                elif 'Dropout' in layer_name:\n",
    "                    continue\n",
    "                else:\n",
    "                    print('not support layer',layer.name)\n",
    "        print('export successfully!')\n",
    "\n",
    "    \n",
    "# model = load_model('./cnn_model_mnist_0-1.h5')\n",
    "# model = load_model('./mnist_model2.h5')\n",
    "# model = load_model('./mnist_model_4106.h5')\n",
    "# model = load_model('./pure_cnn_model_mnist_0-1.h5')\n",
    "# model = load_model('./pure_cnn_model_mnist_stride_1.h5')\n",
    "# model = load_model('./model/mnist/h5/same_s1_k3_cnn.h5')\n",
    "# model = load_model('./model/mnist/h5/mnist_model_4_100_adam.h5')\n",
    "\n",
    "# model.layers[0].get_weights()[0][:,:,0,0]\n",
    "model = load_model('./cifar_cnn_maxpool.h5')\n",
    "# t1,t2,x_test,y_test=preprocessing_data()\n",
    "# score = model.evaluate(x_test,y_test)\n",
    "# print(score)\n",
    "a = Convert2MyTools()\n",
    "a.extract_model(model,'./cifar_cnn_maxpool.v')\n",
    "\n",
    "# print(len(model.layers))\n",
    "# layer = model.layers[2]\n",
    "# print(type(layer).__name__)\n",
    "# print(layer.input_shape)\n",
    "# print(layer.output_shape)\n",
    "# weights = layer.get_weights()\n",
    "# ws = weights[0]\n",
    "# ws[:,:,0,0]\n",
    "# for item in layer.__dict__.items():\n",
    "#     print(item)\n",
    "# print(layer.input_shape)\n",
    "# print(layer.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T06:23:30.455855Z",
     "start_time": "2019-12-24T06:23:30.448378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16])\n",
    "a = a.reshape([2,2,2,2])\n",
    "a[0,0,:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  h5转Mipverify格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T05:27:57.922654Z",
     "start_time": "2019-11-10T05:27:47.011749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 700) (1, 700)\n",
      "(700, 700) (1, 700)\n",
      "(700, 700) (1, 700)\n",
      "(700, 700) (1, 700)\n",
      "(700, 700) (1, 700)\n",
      "(700, 700) (1, 700)\n",
      "(700, 700) (1, 700)\n",
      "(700, 700) (1, 700)\n",
      "(700, 10) (1, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# mipverify抽取参数\n",
    "\n",
    "import scipy.io as sio\n",
    "class Convert2MIPVerify:\n",
    "    \n",
    "    def extract_dense_mat(self,layer,i,param):\n",
    "        weights = layer.get_weights()\n",
    "        ws = weights[0]\n",
    "        bias = weights[1]\n",
    "        param[\"fc\"+str(i)+\"/weight\"] = ws\n",
    "        param[\"fc\"+str(i)+\"/bias\"] = np.transpose(bias.reshape(-1,1))\n",
    "        print(ws.shape,np.transpose(bias.reshape(-1,1)).shape)\n",
    "    \n",
    "    def extract_model(self,model):\n",
    "        param = dict()\n",
    "        sindex=0\n",
    "        for index,layer in enumerate(model.layers):\n",
    "            layer_name = type(layer).__name__\n",
    "            if 'Dropout' in layer_name:\n",
    "                    continue\n",
    "            sindex+=1\n",
    "            self.extract_dense_mat(layer,sindex,param)\n",
    "        sio.savemat(\"{}.mat\".format('mnist_model_8_700'), param)\n",
    "        \n",
    "s = Convert2MIPVerify()\n",
    "model = load_model('./model/mnist/h5/mnist_model_8_700_adam.h5')\n",
    "s.extract_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mipverify转Eran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "model = sio.loadmat(\"./model/mnist/mipverify_model/mnist242.mat\")\n",
    "w_arr = []\n",
    "b_arr = []\n",
    "with open('mnist24.tf', 'w') as fs:\n",
    "    for i in range(1,4):\n",
    "        weights = np.transpose(model[\"fc\"+str(i)+\"/weight\"])\n",
    "        bias = model[\"fc\"+str(i)+\"/bias\"]\n",
    "    #     print(w.shape,b.shape)\n",
    "        fs.write('ReLU\\n')\n",
    "        fs.write(str(weights.tolist())+'\\n')\n",
    "        fs.write(str(bias[0].tolist())+'\\n')        \n",
    "#     weights = np.transpose(model[\"logits/weight\"])\n",
    "#     bias = model[\"logits/bias\"]\n",
    "#     fs.write('ReLU\\n')\n",
    "#     fs.write(str(weights.tolist())+'\\n')\n",
    "#     fs.write(str(bias[0].tolist())+'\\n')     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Please use HDF reader for matlab v7.3 files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ae1ce49698c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/mnist/mipverify_model/mnist24.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# model = dict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[1;32m    140\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatFile5Reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please use HDF reader for matlab v7.3 files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Did not recognize version %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmjv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Please use HDF reader for matlab v7.3 files"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "m = sio.loadmat('model/mnist/mipverify_model/mnist24.mat')\n",
    "# model = dict()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import h5py\n",
    "# mat = h5py.File('model/mnist/mipverify_model/mnist24.mat')\n",
    "\n",
    "# model[\"fc1/weight\"] = np.transpose(mat['fc1_weight'])\n",
    "# model[\"fc1/bias\"] = np.transpose(mat['fc1_bias'])\n",
    "# model[\"fc2/weight\"] = np.transpose(mat['fc2_weight'])\n",
    "# model[\"fc2/bias\"] = np.transpose(mat['fc2_bias'])\n",
    "# model[\"fc3/weight\"] = np.transpose(mat['fc3_weight'])\n",
    "# model[\"fc3/bias\"] = np.transpose(mat['fc3_bias'])\n",
    "# sio.savemat('model/mnist/mipverify_model/mnist242.mat',model)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import scipy.io as sio\n",
    "\n",
    "import numpy as np\n",
    "# import cvxpy as cp\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "Converts saved `.pth` files produced by authors' code to `.mat` files in a\n",
    "format we can process.\n",
    "\"\"\"\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# lpnet_torch = nn.Sequential(\n",
    "#         nn.Conv2d(1, 16, 4, stride=2, padding=1),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Conv2d(16, 32, 4, stride=2, padding=1),\n",
    "#         nn.ReLU(),\n",
    "#         Flatten(),\n",
    "#         nn.Linear(32*7*7,100),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Linear(100, 10)\n",
    "#     )\n",
    "\n",
    "lpnet_torch = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(784, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 10)\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='convert .pth checkpoint file from pytorch training for WK17a networks.')\n",
    "    parser.add_argument('name', help='name of .pth file to be converted')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    name = os.path.splitext(args.name)[0]\n",
    "    checkpoint = torch.load(\"{}.pth\".format(name), map_location=\"cpu\")\n",
    "    lpnet_torch.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    parameters_torch = dict()\n",
    "    # transposing the tensor is necessary because pytorch and Julia have different conventions.\n",
    "    # parameters_torch[\"conv1/weight\"] = np.transpose(lpnet_torch[0].weight.data.numpy(), [2, 3, 1, 0])\n",
    "    # parameters_torch[\"conv1/bias\"] = lpnet_torch[0].bias.data.numpy()\n",
    "    # parameters_torch[\"conv2/weight\"] = np.transpose(lpnet_torch[2].weight.data.numpy(), [2, 3, 1, 0])\n",
    "    # parameters_torch[\"conv2/bias\"] = lpnet_torch[2].bias.data.numpy()\n",
    "    # parameters_torch[\"fc1/weight\"] = np.transpose(lpnet_torch[5].weight.data.numpy())\n",
    "    # parameters_torch[\"fc1/bias\"] = lpnet_torch[5].bias.data.numpy()\n",
    "    # parameters_torch[\"logits/weight\"] = np.transpose(lpnet_torch[7].weight.data.numpy())\n",
    "    # parameters_torch[\"logits/bias\"] = lpnet_torch[7].bias.data.numpy()\n",
    "\n",
    "    #print(lpnet_torch)\n",
    "\n",
    "    parameters_torch[\"fc1/weight\"] = np.transpose(lpnet_torch[1].weight.data.numpy())\n",
    "    parameters_torch[\"fc1/bias\"] = lpnet_torch[1].bias.data.numpy()\n",
    "    parameters_torch[\"fc2/weight\"] = np.transpose(lpnet_torch[3].weight.data.numpy())\n",
    "    parameters_torch[\"fc2/bias\"] = lpnet_torch[3].bias.data.numpy()\n",
    "    parameters_torch[\"fc3/weight\"] = np.transpose(lpnet_torch[5].weight.data.numpy())\n",
    "    parameters_torch[\"fc3/bias\"] = lpnet_torch[5].bias.data.numpy()\n",
    "\n",
    "    sio.savemat(\"{}.mat\".format(name), parameters_torch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_data=[\n",
    "              [[1,0,1,2,1],\n",
    "               [0,2,1,0,1],\n",
    "               [1,1,0,2,0],\n",
    "               [2,2,1,1,0],\n",
    "               [2,0,1,2,0]],\n",
    "\n",
    "               [[2,0,2,1,1],\n",
    "                [0,1,0,0,2],\n",
    "                [1,0,0,2,1],\n",
    "                [1,1,2,1,0],\n",
    "                [1,0,1,1,1]] \n",
    "            ]\n",
    "weights_data=[ \n",
    "               [[ 1, 0, 1],\n",
    "                [-1, 1, 0],\n",
    "                [ 0,-1, 0]],\n",
    "               [[-1, 0, 1],\n",
    "                [ 0, 0, 1],\n",
    "                [ 1, 1, 1]] \n",
    "\n",
    "           ]\n",
    "\n",
    "\n",
    "#fm:[h,w]\n",
    "#kernel:[k,k]\n",
    "#return rs:[h,w] \n",
    "def compute_conv(fm,kernel):\n",
    "    [h,w]=fm.shape\n",
    "    [k,_]=kernel.shape \n",
    "    r=int(k/2)\n",
    "    #定义边界填充0后的map\n",
    "    padding_fm=np.zeros([h+2,w+2],np.float32)\n",
    "    #保存计算结果\n",
    "    rs=np.zeros([h,w],np.float32)\n",
    "    #将输入在指定该区域赋值，即除了4个边界后，剩下的区域\n",
    "    padding_fm[1:h+1,1:w+1]=fm \n",
    "    #对每个点为中心的区域遍历\n",
    "    for i in range(1,h+1):\n",
    "        for j in range(1,w+1): \n",
    "            #取出当前点为中心的k*k区域\n",
    "            roi=padding_fm[i-r:i+r+1,j-r:j+r+1]\n",
    "            #计算当前点的卷积,对k*k个点点乘后求和\n",
    "            rs[i-1][j-1]=np.sum(roi*kernel)\n",
    "\n",
    "    return rs\n",
    "\n",
    "def my_conv2d(input,weights):\n",
    "    [c,h,w]=input.shape\n",
    "    [_,k,_]=weights.shape\n",
    "    outputs=np.zeros([h,w],np.float32)\n",
    "\n",
    "    #对每个feature map遍历，从而对每个feature map进行卷积\n",
    "    for i in range(c):\n",
    "        #feature map==>[h,w]\n",
    "        f_map=input[i]\n",
    "        #kernel ==>[k,k]\n",
    "        w=weights[i]\n",
    "        rs =compute_conv(f_map,w)\n",
    "        outputs=outputs+rs   \n",
    "\n",
    "    return outputs\n",
    "\n",
    "def main():  \n",
    "\n",
    "    #shape=[c,h,w]\n",
    "    input = np.asarray(input_data,np.float32)\n",
    "    #shape=[in_c,k,k]\n",
    "    weights =  np.asarray(weights_data,np.float32) \n",
    "    rs=my_conv2d(input,weights) \n",
    "    print(rs) \n",
    "    \n",
    "# main()\n",
    "np.sum(np.asarray([[1,2],[3,4]])*np.asarray([[1,0],[-1,2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T09:24:03.582343Z",
     "start_time": "2019-10-13T09:24:03.560503Z"
    }
   },
   "source": [
    "# Keras2Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T06:53:24.365008Z",
     "start_time": "2020-01-18T06:52:22.009693Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras2onnx,onnx,onnxruntime\n",
    "\n",
    "model = load_model('resnet_transfer_cifar10.h5')\n",
    "onnx_model = keras2onnx.convert_keras(model,model.name)\n",
    "onnx.save_model(onnx_model,\"resnet_transfer_cifar10.onnx\")\n",
    "# onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T08:36:09.322621Z",
     "start_time": "2020-01-13T08:36:09.309076Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = onnxruntime.InferenceSession(\"cifar_cnn_maxpool.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T06:08:49.299076Z",
     "start_time": "2020-01-18T06:08:38.196042Z"
    }
   },
   "outputs": [],
   "source": [
    "model=load_model('resnet_transfer_cifar10.h5')\n",
    "# for index,layer in enumerate(model.layers):\n",
    "#     print(layer.name,type(layer).__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T06:15:13.349121Z",
     "start_time": "2020-01-18T06:15:13.345240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bn2a_branch2c_2/cond/Merge:0\", shape=(?, 8, 8, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer = model.layers[17]\n",
    "# for item in layer.__dict__.items():\n",
    "#     print(item)\n",
    "# print(layer.input_shape)\n",
    "# print(layer.output_shape)\n",
    "# print(layer.__dir__())\n",
    "# print(layer.input.__dir__())\n",
    "# print(layer.name)\n",
    "# print(layer.input.__dir__())\n",
    "# print(layer.input._op)\n",
    "# print(layer.input.__str__())\n",
    "# print(layer.output._op)\n",
    "# print(layer.output.__dir__())\n",
    "print(layer._inbound_nodes[0].input_tensors[0])\n",
    "\n",
    "# [<tf.Tensor 'bn2a_branch2c/cond/Merge:0' shape=(?, 8, 8, 256) dtype=float32>, <tf.Tensor 'bn2a_branch1/cond/Merge:0' shape=(?, 8, 8, 256) dtype=float32>]\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "tf1.15",
   "language": "python",
   "name": "exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
